{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45492c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (0.12.8)\n",
      "Requirement already satisfied: llama-index-readers-obsidian in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (0.4.0)\n",
      "Requirement already satisfied: ipywidgets in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (8.1.5)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (4.67.1)\n",
      "Requirement already satisfied: ipython in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from -r requirements.txt (line 5)) (8.16.0)\n",
      "Requirement already satisfied: huggingface-hub in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (0.27.0)\n",
      "Requirement already satisfied: openai in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (1.58.1)\n",
      "Requirement already satisfied: pyyaml in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (6.0.2)\n",
      "Requirement already satisfied: llama-index-llms-ollama in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (0.5.0)\n",
      "Requirement already satisfied: llama-index-embeddings-ollama in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (0.5.0)\n",
      "Requirement already satisfied: llama-index-embeddings-huggingface in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (0.4.0)\n",
      "Requirement already satisfied: ipykernel in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from -r requirements.txt (line 12)) (6.25.2)\n",
      "Requirement already satisfied: pyvis in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (0.3.2)\n",
      "Requirement already satisfied: python-dotenv in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (1.0.1)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.8 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.12.8)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.3.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.6.3)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.3.12)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.3.1)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.3.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (3.9.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipywidgets->-r requirements.txt (line 3)) (0.1.4)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipywidgets->-r requirements.txt (line 3)) (5.10.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /opt/homebrew/lib/python3.10/site-packages (from ipywidgets->-r requirements.txt (line 3)) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /opt/homebrew/lib/python3.10/site-packages (from ipywidgets->-r requirements.txt (line 3)) (3.0.13)\n",
      "Requirement already satisfied: backcall in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (0.2.0)\n",
      "Requirement already satisfied: decorator in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (0.19.0)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (2.16.1)\n",
      "Requirement already satisfied: stack-data in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (0.6.2)\n",
      "Requirement already satisfied: exceptiongroup in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (1.1.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (4.8.0)\n",
      "Requirement already satisfied: appnope in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (0.1.3)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub->-r requirements.txt (line 6)) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub->-r requirements.txt (line 6)) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from huggingface-hub->-r requirements.txt (line 6)) (23.1)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub->-r requirements.txt (line 6)) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub->-r requirements.txt (line 6)) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/homebrew/lib/python3.10/site-packages (from openai->-r requirements.txt (line 7)) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/lib/python3.10/site-packages (from openai->-r requirements.txt (line 7)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/lib/python3.10/site-packages (from openai->-r requirements.txt (line 7)) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from openai->-r requirements.txt (line 7)) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/homebrew/lib/python3.10/site-packages (from openai->-r requirements.txt (line 7)) (2.10.4)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/lib/python3.10/site-packages (from openai->-r requirements.txt (line 7)) (1.3.1)\n",
      "Requirement already satisfied: ollama>=0.4.3 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-llms-ollama->-r requirements.txt (line 9)) (0.4.4)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.1 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (3.3.1)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipykernel->-r requirements.txt (line 12)) (1.8.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipykernel->-r requirements.txt (line 12)) (8.3.1)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipykernel->-r requirements.txt (line 12)) (5.3.2)\n",
      "Requirement already satisfied: nest-asyncio in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipykernel->-r requirements.txt (line 12)) (1.5.8)\n",
      "Requirement already satisfied: psutil in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipykernel->-r requirements.txt (line 12)) (5.9.5)\n",
      "Requirement already satisfied: pyzmq>=20 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipykernel->-r requirements.txt (line 12)) (25.1.1)\n",
      "Requirement already satisfied: tornado>=6.1 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipykernel->-r requirements.txt (line 12)) (6.3.3)\n",
      "Requirement already satisfied: jinja2>=2.9.6 in /opt/homebrew/lib/python3.10/site-packages (from pyvis->-r requirements.txt (line 13)) (3.1.5)\n",
      "Requirement already satisfied: jsonpickle>=1.4.1 in /opt/homebrew/lib/python3.10/site-packages (from pyvis->-r requirements.txt (line 13)) (4.0.1)\n",
      "Requirement already satisfied: networkx>=1.11 in /opt/homebrew/lib/python3.10/site-packages (from pyvis->-r requirements.txt (line 13)) (3.4.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/homebrew/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 7)) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 7)) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 7)) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 7)) (0.14.0)\n",
      "Requirement already satisfied: aiohttp in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (3.11.11)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from jedi>=0.16->ipython->-r requirements.txt (line 5)) (0.8.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.10/site-packages (from jinja2>=2.9.6->pyvis->-r requirements.txt (line 13)) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 12)) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 12)) (3.10.0)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /opt/homebrew/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (2.0.36)\n",
      "Requirement already satisfied: dataclasses-json in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (10.0.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (0.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: llama-cloud>=0.1.5 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index->-r requirements.txt (line 1)) (0.1.7)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (4.12.3)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (2.2.1)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (5.1.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 1)) (0.5.18)\n",
      "Requirement already satisfied: click in /opt/homebrew/lib/python3.10/site-packages (from nltk>3.8.1->llama-index->-r requirements.txt (line 1)) (8.1.8)\n",
      "Requirement already satisfied: joblib in /opt/homebrew/lib/python3.10/site-packages (from nltk>3.8.1->llama-index->-r requirements.txt (line 1)) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/homebrew/lib/python3.10/site-packages (from nltk>3.8.1->llama-index->-r requirements.txt (line 1)) (2024.11.6)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from pexpect>4.3->ipython->-r requirements.txt (line 5)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython->-r requirements.txt (line 5)) (0.2.7)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/homebrew/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 7)) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.10/site-packages (from requests->huggingface-hub->-r requirements.txt (line 6)) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.10/site-packages (from requests->huggingface-hub->-r requirements.txt (line 6)) (2.3.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (4.47.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.6.0)\n",
      "Requirement already satisfied: scipy in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.14.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from stack-data->ipython->-r requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from stack-data->ipython->-r requirements.txt (line 5)) (2.4.0)\n",
      "Requirement already satisfied: pure-eval in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from stack-data->ipython->-r requirements.txt (line 5)) (0.2.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.18.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from asttokens>=2.1.0->stack-data->ipython->-r requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/homebrew/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (2.6)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/homebrew/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (3.1.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/homebrew/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/homebrew/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/homebrew/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (0.4.5)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/homebrew/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/homebrew/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (3.23.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.10/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/lib/python3.10/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (3.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "614fc4e2-0e04-49b0-bf7c-05efee48933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.obsidian import ObsidianReader\n",
    "from llama_index.core.memory.chat_memory_buffer import MessageRole\n",
    "from llama_index.core import SimpleDirectoryReader, KnowledgeGraphIndex, VectorStoreIndex\n",
    "from llama_index.core.graph_stores import SimpleGraphStore\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "from llama_index.core import Document, PropertyGraphIndex\n",
    "from llama_index.core.storage.index_store import SimpleIndexStore\n",
    "from llama_index.core.vector_stores import SimpleVectorStore\n",
    "from llama_index.core import Settings\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import os\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "import logging\n",
    "import sys\n",
    "import ipywidgets as widgets\n",
    "import json\n",
    "from llama_index.core.callbacks import CallbackManager\n",
    "from llama_index.core.callbacks import LlamaDebugHandler\n",
    "from llama_index.core import ServiceContext\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.retrievers import KnowledgeGraphRAGRetriever\n",
    "from llama_index.core.indices.property_graph import (\n",
    "    SimpleLLMPathExtractor,\n",
    "    SchemaLLMPathExtractor,\n",
    "    DynamicLLMPathExtractor,\n",
    ")\n",
    "import yaml\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5e9f925-0bd9-406c-a41d-8be268260b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    load_index_from_storage,\n",
    "    load_indices_from_storage,\n",
    "    load_graph_from_storage,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8291822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17dd9f9d-7e21-49ef-9a01-d8b0dd7fdc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9954a1",
   "metadata": {},
   "source": [
    "# Set LLM (OpenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a66b699",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  # Charge les variables depuis le fichier .env\n",
    "api_key = os.getenv(\"OPENAI_API_KEY_UP\")\n",
    "# Modifier ou ajouter une variable d'environnement\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f9e96ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, model=\"gpt-4o\", max_tokens=3000)\n",
    "Settings.llm = llm\n",
    "Settings.chunk_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512d7bc2",
   "metadata": {},
   "source": [
    "# Set local LLM for embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa4bc549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "INFO:sentence_transformers.SentenceTransformer:2 prompts are loaded, with the keys: ['query', 'text']\n",
      "2 prompts are loaded, with the keys: ['query', 'text']\n",
      "2 prompts are loaded, with the keys: ['query', 'text']\n"
     ]
    }
   ],
   "source": [
    "# bge-base embedding model\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "#Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7a4b82",
   "metadata": {},
   "source": [
    "# Set LLM for chat  (Local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d46a1ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm = Ollama(model=\"tinyllama\", request_timeout=120.0)\n",
    "#Settings.llm = llm\n",
    "#Settings.chunk_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bc9d70",
   "metadata": {},
   "source": [
    "# Test LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d810955e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "assistant: As a data governance consultant, I don't have personal preferences or feelings, but I can certainly highlight some popular data tools that are widely appreciated in the industry for their capabilities. Tools like Collibra, Informatica, and Alation are often favored for their robust data governance features, including data cataloging, data lineage, and metadata management. These tools help organizations ensure data quality, compliance, and effective data management. The choice of tool often depends on the specific needs and existing infrastructure of an organization.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"You are a data governance consultant\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"What's your favorite data tool ?\"),\n",
    "]\n",
    "resp = llm.chat(messages)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47252b4e-eb58-453c-9e7d-bab5286ee296",
   "metadata": {},
   "source": [
    "# Load storage contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1e8019-e150-4a60-b59d-cac7a4aebcba",
   "metadata": {},
   "source": [
    "## Load vector storage context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42c55a04-2b21-4c05-96fb-f0f9ce26bb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_storage_context = StorageContext.from_defaults(\n",
    "    docstore=SimpleDocumentStore.from_persist_dir(persist_dir=\"vector\"),\n",
    "    vector_store=SimpleVectorStore.from_persist_dir(\n",
    "        persist_dir=\"vector\"\n",
    "    ),\n",
    "    index_store=SimpleIndexStore.from_persist_dir(persist_dir=\"vector\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564b951a-9776-46da-9309-142acfc3f1dd",
   "metadata": {},
   "source": [
    "## Load knowledge graph storage context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a086ef48-3be3-4a12-b158-4ed50aa2b917",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_storage_context = StorageContext.from_defaults(\n",
    "    docstore=SimpleDocumentStore.from_persist_dir(persist_dir=\"knowledge_graph\"),\n",
    "    graph_store=SimpleGraphStore.from_persist_dir(\n",
    "        persist_dir=\"knowledge_graph\"\n",
    "    ),\n",
    "    index_store=SimpleIndexStore.from_persist_dir(persist_dir=\"knowledge_graph\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28317dfb",
   "metadata": {},
   "source": [
    "## Load onto graph storage context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db73d4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "onto_storage_context = StorageContext.from_defaults(\n",
    "    docstore=SimpleDocumentStore.from_persist_dir(persist_dir=\"onto_graph\"),\n",
    "    graph_store=SimpleGraphStore.from_persist_dir(\n",
    "        persist_dir=\"onto_graph\"\n",
    "    ),\n",
    "    index_store=SimpleIndexStore.from_persist_dir(persist_dir=\"onto_graph\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d278b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StorageContext(docstore=<llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore object at 0x17161d270>, index_store=<llama_index.core.storage.index_store.simple_index_store.SimpleIndexStore object at 0x17fc452a0>, vector_stores={'default': SimpleVectorStore(stores_text=False, is_embedding_query=True, data=SimpleVectorStoreData(embedding_dict={}, text_id_to_ref_doc_id={}, metadata_dict={})), 'image': SimpleVectorStore(stores_text=False, is_embedding_query=True, data=SimpleVectorStoreData(embedding_dict={}, text_id_to_ref_doc_id={}, metadata_dict={}))}, graph_store=<llama_index.core.graph_stores.simple.SimpleGraphStore object at 0x17161e350>, property_graph_store=None)\n"
     ]
    }
   ],
   "source": [
    "print(onto_storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261c3f5b-f0fa-4e10-85fd-9ff7642de428",
   "metadata": {},
   "source": [
    "# Load index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb3e85a-8fca-4138-9ff9-fca4637a47e2",
   "metadata": {},
   "source": [
    "## Load vector index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68274006-61a7-42d7-9556-6ddae87d2b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.loading:Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n"
     ]
    }
   ],
   "source": [
    "simple_index = load_index_from_storage(vector_storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cdab09-2c63-4e23-9ca3-79102db74cf0",
   "metadata": {},
   "source": [
    "### Set retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6c3e925-229f-4636-a7b7-73687a3aa7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_query_engine = simple_index.as_query_engine(\n",
    " include_text=True,\n",
    " response_mode=\"tree_summarize\",\n",
    " embedding_mode=\"hybrid\",\n",
    " similarity_top_k=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7b32a3",
   "metadata": {},
   "source": [
    "### Test retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "887f57e4-8bc9-440b-a84c-0080cbd412e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "625287161a8547b2b320478bc0db9662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "simple_rag_retriever = simple_index.as_retriever(\n",
    "    retriever_mode=\"hybrid\",  # or \"embedding\" or \"hybrid\"\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "response = simple_query_engine.query(\n",
    "    \"Je dois lancer un nouveau projet data avec mes données opérationnelles, qui puis-je impliquer, et pour faire quoi ?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f014fd60-81a4-4b7f-aef9-f545402e0fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour lancer un nouveau projet data avec vos données opérationnelles, vous pouvez impliquer plusieurs personnes et équipes clés :\n",
       "\n",
       "1. **Mme Laurent** : Elle a exprimé le besoin d'accéder à des données plus complètes et en temps réel. Vous pouvez l'impliquer pour définir les besoins en données et les indicateurs clés de performance (KPIs) à suivre.\n",
       "\n",
       "2. **M. Dupont** : En tant que Directeur de production, il peut être impliqué pour s'assurer que les données sont complètes et fiables. Il peut également aider à identifier les champs critiques dans le Datawarehouse et à mettre en place des contrôles automatiques pour garantir la qualité des données.\n",
       "\n",
       "3. **Équipes IT** : Elles seront essentielles pour la mise en place des processus ETL, la validation des données, et la gestion de l'infrastructure technique nécessaire pour le projet.\n",
       "\n",
       "4. **Équipes Opérationnelles** : Elles doivent être formées pour comprendre l'importance de la saisie complète des données et pour collaborer avec les équipes IT afin de définir les priorités des données critiques.\n",
       "\n",
       "5. **Responsable de la Base Opération** : Cette personne peut aider à fournir une documentation claire et détaillée de la base de données \"Opérations\" pour garantir une compréhension commune et faciliter l'utilisation et la maintenance de la base.\n",
       "\n",
       "Ensemble, ces parties prenantes peuvent collaborer pour assurer le succès du projet en garantissant que les données opérationnelles sont bien gérées, complètes, et utilisées efficacement pour atteindre vos objectifs.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4242ad8d-20fb-4126-9380-4d51c7e3fa32",
   "metadata": {},
   "source": [
    "## Load graph index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75e3c260-c349-43f0-b54c-6dac7a12586f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.loading:Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n"
     ]
    }
   ],
   "source": [
    "graph_index = load_index_from_storage(graph_storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81c1e83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = graph_index.get_networkx_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8424ed30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in the knowledge graph: 87\n"
     ]
    }
   ],
   "source": [
    "# Count the number of nodes\n",
    "num_nodes = len(nx_graph.edges())\n",
    "\n",
    "print(f\"Number of nodes in the knowledge graph: {num_nodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0388bce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 116 nodes and 87 edges\n",
      "Nodes: ['Document', 'Aspects techniques du datawarehouse', 'Spécifications des flux de données', 'Caractéristiques techniques', 'Description', 'Datawarehouse', 'Réservoir central', 'Données consolidées', 'Élément crucial', 'Fiabilité', 'Postgresql 14', 'Base de données', 'Modèle en étoile', 'Structure', 'Directeur de la production', 'Accès', 'Politiques strictes', 'Administrateurs système', 'Indirect', 'Contrats', 'Erp', 'Système central de gestion', 'Données relatives à', 'Visibilité en temps réel', 'Interfaces', 'Transfert des données', 'Informations précises et à jour', 'Interface', 'Etl', 'Outil', 'Talend data integration', 'Source', 'Erp (sap', 'Destination', 'Tables de faits et dimensions du datawarehouse', 'Planification', 'Ordonnanceur cron', 'Alertes', \"Emails et logs en cas d'échec\", 'Gestion', 'Données', 'Fragmentées', 'Validation', 'Contrôles sur les types et les règles métier', 'Reporting', 'Tableau de bord sur les échecs de flux', 'Rétention', '7 ans', 'Archivage', 'Compression et stockage sur un serveur sftp', 'Contraintes', 'Risques', 'Pertes de données', 'Erreurs de transformation', 'Temps de latence', 'Erp et datawarehouse', 'Maintenance', 'Interfaces etl', 'Entite', 'Personne physique', 'Field', 'Base personne', 'Crm', 'Membre ecosysteme 1', 'Responsables de production', 'Besoins', 'Problématiques', 'Julien morel', 'Monsieur', 'M. morel', 'Difficultés liées au suivi des stocks', 'Manque de coordination entre équipes de production', 'Suivi centralisé et automatisé des stocks critiques avec alertes préventives', 'Meilleure intégration des plannings des équipes dans l’erp', 'M. martin', 'Ajout module gestion des stocks avancé erp', 'Amélioration outils collaboratifs système', 'Options', 'Mise à disposition d’un portail d’analyse', 'Création d’un dashboard', 'Intégration d’un système d’alertes', 'Base operation', 'Segmentation des audiences', 'Applicatif de gestion des relations clients', 'Centraliser organiser exploiter informations', 'Acces', '[[base operation]]', 'M. dupont', 'Importance complétude des champs', 'Actions suivantes', 'Mise en place de contrôles automatiques', 'Besoin d’accéder à des données plus complètes', 'Performances des fournisseurs', 'Historique des commandes', 'Données complètes', 'Identifier goulets d’étranglement', 'Dupont', 'Problèmes liés à la situation actuelle', 'Amélioration des relations fournisseurs', 'Réduction des dépenses', 'Données de production', 'Certaines périodes', 'Assurer complétude des données', 'Précision accrue des kpi', 'Gain de temps pour équipes d’analyse', 'Identification', 'Organisation', 'Équipes opérationnelles', 'Complétude des informations', 'Taux d’ouverture des e-mails', 'Pertinence des messages', 'Emails', 'Thomas dupont', 'Besoins d’accès à la base opération', 'Gestion des achats', 'Accès direct']\n",
      "Edges: [('Document', 'Aspects techniques du datawarehouse'), ('Document', 'Spécifications des flux de données'), ('Document', 'Caractéristiques techniques'), ('Description', 'Datawarehouse'), ('Description', 'Erp'), ('Datawarehouse', 'Réservoir central'), ('Datawarehouse', 'Données consolidées'), ('Datawarehouse', 'Élément crucial'), ('Datawarehouse', 'Fiabilité'), ('Datawarehouse', 'Directeur de la production'), ('Datawarehouse', 'Erp'), ('Datawarehouse', 'Entite'), ('Datawarehouse', 'Acces'), ('Datawarehouse', 'Identification'), ('Postgresql 14', 'Base de données'), ('Modèle en étoile', 'Structure'), ('Accès', 'Politiques strictes'), ('Accès', 'Administrateurs système'), ('Accès', 'Indirect'), ('Contrats', 'Erp'), ('Erp', 'Système central de gestion'), ('Erp', 'Données relatives à'), ('Erp', 'Visibilité en temps réel'), ('Erp', 'Données'), ('Erp', 'Entite'), ('Interfaces', 'Transfert des données'), ('Interfaces', 'Informations précises et à jour'), ('Interface', 'Etl'), ('Outil', 'Talend data integration'), ('Source', 'Erp (sap'), ('Destination', 'Tables de faits et dimensions du datawarehouse'), ('Planification', 'Ordonnanceur cron'), ('Alertes', \"Emails et logs en cas d'échec\"), ('Gestion', 'Données'), ('Données', 'Fragmentées'), ('Validation', 'Contrôles sur les types et les règles métier'), ('Reporting', 'Tableau de bord sur les échecs de flux'), ('Rétention', '7 ans'), ('Archivage', 'Compression et stockage sur un serveur sftp'), ('Contraintes', 'Risques'), ('Risques', 'Pertes de données'), ('Risques', 'Erreurs de transformation'), ('Temps de latence', 'Erp et datawarehouse'), ('Maintenance', 'Interfaces etl'), ('Entite', 'Personne physique'), ('Entite', 'Field'), ('Entite', 'Base personne'), ('Entite', 'Crm'), ('Entite', 'Membre ecosysteme 1'), ('Field', 'Base operation'), ('Base personne', 'Segmentation des audiences'), ('Crm', 'Applicatif de gestion des relations clients'), ('Crm', 'Centraliser organiser exploiter informations'), ('Crm', 'Emails'), ('Responsables de production', 'Besoins'), ('Responsables de production', 'Problématiques'), ('Julien morel', 'Monsieur'), ('M. morel', 'Difficultés liées au suivi des stocks'), ('M. morel', 'Manque de coordination entre équipes de production'), ('M. morel', 'Suivi centralisé et automatisé des stocks critiques avec alertes préventives'), ('M. morel', 'Meilleure intégration des plannings des équipes dans l’erp'), ('M. martin', 'Ajout module gestion des stocks avancé erp'), ('M. martin', 'Amélioration outils collaboratifs système'), ('M. martin', 'Options'), ('M. martin', 'Mise à disposition d’un portail d’analyse'), ('M. martin', 'Création d’un dashboard'), ('M. martin', 'Intégration d’un système d’alertes'), ('Acces', '[[base operation]]'), ('M. dupont', 'Importance complétude des champs'), ('M. dupont', 'Actions suivantes'), ('M. dupont', 'Mise en place de contrôles automatiques'), ('M. dupont', 'Besoin d’accéder à des données plus complètes'), ('M. dupont', 'Performances des fournisseurs'), ('M. dupont', 'Historique des commandes'), ('Performances des fournisseurs', 'Accès direct'), ('Données complètes', 'Identifier goulets d’étranglement'), ('Dupont', 'Problèmes liés à la situation actuelle'), ('Dupont', 'Amélioration des relations fournisseurs'), ('Dupont', 'Réduction des dépenses'), ('Données de production', 'Certaines périodes'), ('Assurer complétude des données', 'Précision accrue des kpi'), ('Assurer complétude des données', 'Gain de temps pour équipes d’analyse'), ('Organisation', 'Équipes opérationnelles'), ('Complétude des informations', 'Taux d’ouverture des e-mails'), ('Complétude des informations', 'Pertinence des messages'), ('Thomas dupont', 'Besoins d’accès à la base opération'), ('Thomas dupont', 'Gestion des achats')]\n"
     ]
    }
   ],
   "source": [
    "g = graph_index.get_networkx_graph()\n",
    "print(g)\n",
    "print(\"Nodes:\", g.nodes())\n",
    "print(\"Edges:\", g.edges())\n",
    "net = Network(notebook=True, cdn_resources=\"in_line\", directed=True)\n",
    "net.from_nx(g)\n",
    "\n",
    "with open(\"knowledge_graph.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(net.generate_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3d6f30",
   "metadata": {},
   "source": [
    "### Set retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "330e38ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_query_engine = graph_index.as_query_engine(\n",
    " include_text=True,\n",
    " response_mode=\"tree_summarize\",\n",
    " embedding_mode=\"hybrid\",\n",
    " similarity_top_k=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96e323b",
   "metadata": {},
   "source": [
    "### Test retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0dd0ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2508293418d4a7c9fd13db6c38e79df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 4a9725f2-a5cd-47ab-a5cf-c6ff2c957b8e: 5.2 Risques\n",
      "\n",
      "- Panne des interfaces ETL pouvant interrompre les flux de donné...\n",
      "> Querying with idx: 4a9725f2-a5cd-47ab-a5cf-c6ff2c957b8e: 5.2 Risques\n",
      "\n",
      "- Panne des interfaces ETL pouvant interrompre les flux de donné...\n",
      "> Querying with idx: 4a9725f2-a5cd-47ab-a5cf-c6ff2c957b8e: 5.2 Risques\n",
      "\n",
      "- Panne des interfaces ETL pouvant interrompre les flux de donné...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 08b06ef3-6916-491a-a44d-31cf8e4fa62c: ---\n",
      "entite: applicatif\n",
      "feeds: \"[[Datawarehouse]]\"\n",
      "---\n",
      "Ce document détaille le...\n",
      "> Querying with idx: 08b06ef3-6916-491a-a44d-31cf8e4fa62c: ---\n",
      "entite: applicatif\n",
      "feeds: \"[[Datawarehouse]]\"\n",
      "---\n",
      "Ce document détaille le...\n",
      "> Querying with idx: 08b06ef3-6916-491a-a44d-31cf8e4fa62c: ---\n",
      "entite: applicatif\n",
      "feeds: \"[[Datawarehouse]]\"\n",
      "---\n",
      "Ce document détaille le...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 0ef83e4e-956b-4a9a-a07c-c98c95636658: ---\n",
      "entite: base\n",
      "---\n",
      "Ce document a pour objectif de décrire les aspects techn...\n",
      "> Querying with idx: 0ef83e4e-956b-4a9a-a07c-c98c95636658: ---\n",
      "entite: base\n",
      "---\n",
      "Ce document a pour objectif de décrire les aspects techn...\n",
      "> Querying with idx: 0ef83e4e-956b-4a9a-a07c-c98c95636658: ---\n",
      "entite: base\n",
      "---\n",
      "Ce document a pour objectif de décrire les aspects techn...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 6ffd556c-718a-46fb-a6f6-6e30001b1a62: ---\n",
      "entite: base\n",
      "parent: \"[[ERP]]\"\n",
      "---\n",
      "La base de données \"Opérations\" est un...\n",
      "> Querying with idx: 6ffd556c-718a-46fb-a6f6-6e30001b1a62: ---\n",
      "entite: base\n",
      "parent: \"[[ERP]]\"\n",
      "---\n",
      "La base de données \"Opérations\" est un...\n",
      "> Querying with idx: 6ffd556c-718a-46fb-a6f6-6e30001b1a62: ---\n",
      "entite: base\n",
      "parent: \"[[ERP]]\"\n",
      "---\n",
      "La base de données \"Opérations\" est un...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: eb770add-bc93-41ea-b08c-3dad0d299bfb: Prochaines Étapes\n",
      "\n",
      "1. Identification des champs critiques et prioritaires dan...\n",
      "> Querying with idx: eb770add-bc93-41ea-b08c-3dad0d299bfb: Prochaines Étapes\n",
      "\n",
      "1. Identification des champs critiques et prioritaires dan...\n",
      "> Querying with idx: eb770add-bc93-41ea-b08c-3dad0d299bfb: Prochaines Étapes\n",
      "\n",
      "1. Identification des champs critiques et prioritaires dan...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: ced72763-e189-4b56-94ca-e3fe1ed56697: 5.1 Contraintes\n",
      "\n",
      "- Temps de latence entre l’ERP et le Datawarehouse\n",
      "- Complex...\n",
      "> Querying with idx: ced72763-e189-4b56-94ca-e3fe1ed56697: 5.1 Contraintes\n",
      "\n",
      "- Temps de latence entre l’ERP et le Datawarehouse\n",
      "- Complex...\n",
      "> Querying with idx: ced72763-e189-4b56-94ca-e3fe1ed56697: 5.1 Contraintes\n",
      "\n",
      "- Temps de latence entre l’ERP et le Datawarehouse\n",
      "- Complex...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 2d93f7b2-4f8f-4f21-88fc-573dc718e68f: 6. Conclusion\n",
      "\n",
      "L’ERP joue un rôle essentiel dans l’alimentation du Datawareho...\n",
      "> Querying with idx: 2d93f7b2-4f8f-4f21-88fc-573dc718e68f: 6. Conclusion\n",
      "\n",
      "L’ERP joue un rôle essentiel dans l’alimentation du Datawareho...\n",
      "> Querying with idx: 2d93f7b2-4f8f-4f21-88fc-573dc718e68f: 6. Conclusion\n",
      "\n",
      "L’ERP joue un rôle essentiel dans l’alimentation du Datawareho...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: b51fda10-72af-4ac6-bab9-edd7267fd758: Relations avec d'autres Tables\n",
      "\n",
      "- **Table `utilisateurs`** :\n",
      "    - Relation p...\n",
      "> Querying with idx: b51fda10-72af-4ac6-bab9-edd7267fd758: Relations avec d'autres Tables\n",
      "\n",
      "- **Table `utilisateurs`** :\n",
      "    - Relation p...\n",
      "> Querying with idx: b51fda10-72af-4ac6-bab9-edd7267fd758: Relations avec d'autres Tables\n",
      "\n",
      "- **Table `utilisateurs`** :\n",
      "    - Relation p...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 0b6ed73f-12a4-4242-a2df-b61584f5b55a: 3. Contrats d'Interface avec l'ERP\n",
      "> Querying with idx: 0b6ed73f-12a4-4242-a2df-b61584f5b55a: 3. Contrats d'Interface avec l'ERP\n",
      "> Querying with idx: 0b6ed73f-12a4-4242-a2df-b61584f5b55a: 3. Contrats d'Interface avec l'ERP\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 93f4fbfa-1d6a-4ed2-8abb-98aba87976d2: Ajout d'une Opération\n",
      "\n",
      "```sql\n",
      "INSERT INTO operations (nom_op, description_op,...\n",
      "> Querying with idx: 93f4fbfa-1d6a-4ed2-8abb-98aba87976d2: Ajout d'une Opération\n",
      "\n",
      "```sql\n",
      "INSERT INTO operations (nom_op, description_op,...\n",
      "> Querying with idx: 93f4fbfa-1d6a-4ed2-8abb-98aba87976d2: Ajout d'une Opération\n",
      "\n",
      "```sql\n",
      "INSERT INTO operations (nom_op, description_op,...\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "graph_rag_retriever = graph_index.as_retriever(\n",
    "    retriever_mode=\"hybrid\",  # or \"embedding\" or \"hybrid\"\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "response = graph_query_engine.query(\n",
    "    \"Je dois lancer un nouveau projet data avec mes données opérationnelles, qui puis-je impliquer, et pour faire quoi ?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1031a44-f06e-400f-beaa-2065beeee9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour lancer un nouveau projet data avec vos données opérationnelles, vous pouvez impliquer plusieurs parties prenantes et définir des rôles spécifiques :\n",
       "\n",
       "1. **Équipes Opérationnelles** : Organisez une formation pour ces équipes afin de les préparer à gérer et analyser les données opérationnelles. Elles joueront un rôle clé dans la collecte et la validation des données.\n",
       "\n",
       "2. **Équipe IT/Technique** : Impliquez-les pour gérer les aspects techniques du Datawarehouse, y compris les flux de données et les transformations nécessaires. Ils seront responsables de la mise en place des règles de validation automatique dans les processus ETL.\n",
       "\n",
       "3. **Responsables de Projet** : Assurez-vous d'avoir un responsable de projet qui peut coordonner les différentes équipes et s'assurer que le projet respecte les délais et les objectifs fixés.\n",
       "\n",
       "4. **Analystes de Données** : Ils seront essentiels pour l'analyse et l'interprétation des données, permettant de tirer des insights stratégiques pour l'entreprise.\n",
       "\n",
       "5. **Gestionnaires de l'ERP** : Puisque l'ERP alimente le Datawarehouse, il est crucial d'impliquer ceux qui gèrent l'ERP pour garantir la synchronisation et la fiabilité des données.\n",
       "\n",
       "Ensemble, ces parties prenantes peuvent collaborer pour assurer le succès de votre projet data en utilisant efficacement les données opérationnelles.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1e7541",
   "metadata": {},
   "source": [
    "## Load onto index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb203e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.loading:Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n"
     ]
    }
   ],
   "source": [
    "onto_storage_context = StorageContext.from_defaults(persist_dir=\"onto_graph\")\n",
    "# Load the PropertyGraphIndex from the storage context\n",
    "\n",
    "onto_index = load_index_from_storage(onto_storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a182d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "onto_index.property_graph_store.save_networkx_graph(\n",
    "    name=\"OntoGraph.html\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e4dcae",
   "metadata": {},
   "source": [
    "### Set retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bee17732",
   "metadata": {},
   "outputs": [],
   "source": [
    "onto_query_engine = onto_index.as_query_engine(\n",
    " include_text=True,\n",
    " similarity_top_k=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95920ba",
   "metadata": {},
   "source": [
    "### Test retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4c400086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0934200c08c34ba99e30ce87cde665ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "onto_rag_retriever = onto_index.as_retriever(\n",
    "    retriever_mode=\"hybrid\",  # or \"embedding\" or \"hybrid\"\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "response = onto_query_engine.query(\n",
    "    \"Je dois lancer un nouveau projet data avec mes données opérationnelles, qui puis-je impliquer, et pour faire quoi ?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "123366e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour lancer un nouveau projet data avec vos données opérationnelles, vous pouvez impliquer plusieurs parties prenantes et définir des rôles spécifiques :\n",
       "\n",
       "1. **Équipes Opérationnelles et IT** : Collaborez étroitement avec ces équipes pour définir les priorités des données critiques et assurer une intégration fluide des données dans le Datawarehouse.\n",
       "\n",
       "2. **Responsable de Projet** : Une personne comme Jean Dupont, qui a déjà une expérience dans la gestion des opérations, pourrait être responsable de superviser le projet et de coordonner les différentes équipes.\n",
       "\n",
       "3. **Équipe de Formation** : Organisez une session de formation pour les équipes terrain afin de les sensibiliser à l'importance de la saisie complète des données dans l'ERP, ce qui est crucial pour la qualité des données opérationnelles.\n",
       "\n",
       "4. **Spécialistes en ETL** : Mettez en place des contrôles automatiques pour détecter et signaler les champs manquants lors des processus ETL, garantissant ainsi la fiabilité des données transférées.\n",
       "\n",
       "5. **Développeurs** : Développez un accès personnalisé avec une interface d'utilisation pour faciliter l'interaction avec les données opérationnelles.\n",
       "\n",
       "Ces rôles et actions contribueront à la réussite de votre projet data en assurant une gestion efficace des données opérationnelles.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474b65be-955e-44db-942e-27e235384f19",
   "metadata": {},
   "source": [
    "# Visualize knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "55ef03a2-2e7e-443d-865f-b6d991d16416",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = graph_index.get_networkx_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9d58e14-0017-494f-98ec-ad8b30bf8c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in the knowledge graph: 87\n"
     ]
    }
   ],
   "source": [
    "# Count the number of nodes\n",
    "num_nodes = len(nx_graph.edges())\n",
    "\n",
    "print(f\"Number of nodes in the knowledge graph: {num_nodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a113918c-f195-4c8c-b0f3-c85d7a6c5d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 116 nodes and 87 edges\n",
      "Nodes: ['Document', 'Aspects techniques du datawarehouse', 'Spécifications des flux de données', 'Caractéristiques techniques', 'Description', 'Datawarehouse', 'Réservoir central', 'Données consolidées', 'Élément crucial', 'Fiabilité', 'Postgresql 14', 'Base de données', 'Modèle en étoile', 'Structure', 'Directeur de la production', 'Accès', 'Politiques strictes', 'Administrateurs système', 'Indirect', 'Contrats', 'Erp', 'Système central de gestion', 'Données relatives à', 'Visibilité en temps réel', 'Interfaces', 'Transfert des données', 'Informations précises et à jour', 'Interface', 'Etl', 'Outil', 'Talend data integration', 'Source', 'Erp (sap', 'Destination', 'Tables de faits et dimensions du datawarehouse', 'Planification', 'Ordonnanceur cron', 'Alertes', \"Emails et logs en cas d'échec\", 'Gestion', 'Données', 'Fragmentées', 'Validation', 'Contrôles sur les types et les règles métier', 'Reporting', 'Tableau de bord sur les échecs de flux', 'Rétention', '7 ans', 'Archivage', 'Compression et stockage sur un serveur sftp', 'Contraintes', 'Risques', 'Pertes de données', 'Erreurs de transformation', 'Temps de latence', 'Erp et datawarehouse', 'Maintenance', 'Interfaces etl', 'Entite', 'Personne physique', 'Field', 'Base personne', 'Crm', 'Membre ecosysteme 1', 'Responsables de production', 'Besoins', 'Problématiques', 'Julien morel', 'Monsieur', 'M. morel', 'Difficultés liées au suivi des stocks', 'Manque de coordination entre équipes de production', 'Suivi centralisé et automatisé des stocks critiques avec alertes préventives', 'Meilleure intégration des plannings des équipes dans l’erp', 'M. martin', 'Ajout module gestion des stocks avancé erp', 'Amélioration outils collaboratifs système', 'Options', 'Mise à disposition d’un portail d’analyse', 'Création d’un dashboard', 'Intégration d’un système d’alertes', 'Base operation', 'Segmentation des audiences', 'Applicatif de gestion des relations clients', 'Centraliser organiser exploiter informations', 'Acces', '[[base operation]]', 'M. dupont', 'Importance complétude des champs', 'Actions suivantes', 'Mise en place de contrôles automatiques', 'Besoin d’accéder à des données plus complètes', 'Performances des fournisseurs', 'Historique des commandes', 'Données complètes', 'Identifier goulets d’étranglement', 'Dupont', 'Problèmes liés à la situation actuelle', 'Amélioration des relations fournisseurs', 'Réduction des dépenses', 'Données de production', 'Certaines périodes', 'Assurer complétude des données', 'Précision accrue des kpi', 'Gain de temps pour équipes d’analyse', 'Identification', 'Organisation', 'Équipes opérationnelles', 'Complétude des informations', 'Taux d’ouverture des e-mails', 'Pertinence des messages', 'Emails', 'Thomas dupont', 'Besoins d’accès à la base opération', 'Gestion des achats', 'Accès direct']\n",
      "Edges: [('Document', 'Aspects techniques du datawarehouse'), ('Document', 'Spécifications des flux de données'), ('Document', 'Caractéristiques techniques'), ('Description', 'Datawarehouse'), ('Description', 'Erp'), ('Datawarehouse', 'Réservoir central'), ('Datawarehouse', 'Données consolidées'), ('Datawarehouse', 'Élément crucial'), ('Datawarehouse', 'Fiabilité'), ('Datawarehouse', 'Directeur de la production'), ('Datawarehouse', 'Erp'), ('Datawarehouse', 'Entite'), ('Datawarehouse', 'Acces'), ('Datawarehouse', 'Identification'), ('Postgresql 14', 'Base de données'), ('Modèle en étoile', 'Structure'), ('Accès', 'Politiques strictes'), ('Accès', 'Administrateurs système'), ('Accès', 'Indirect'), ('Contrats', 'Erp'), ('Erp', 'Système central de gestion'), ('Erp', 'Données relatives à'), ('Erp', 'Visibilité en temps réel'), ('Erp', 'Données'), ('Erp', 'Entite'), ('Interfaces', 'Transfert des données'), ('Interfaces', 'Informations précises et à jour'), ('Interface', 'Etl'), ('Outil', 'Talend data integration'), ('Source', 'Erp (sap'), ('Destination', 'Tables de faits et dimensions du datawarehouse'), ('Planification', 'Ordonnanceur cron'), ('Alertes', \"Emails et logs en cas d'échec\"), ('Gestion', 'Données'), ('Données', 'Fragmentées'), ('Validation', 'Contrôles sur les types et les règles métier'), ('Reporting', 'Tableau de bord sur les échecs de flux'), ('Rétention', '7 ans'), ('Archivage', 'Compression et stockage sur un serveur sftp'), ('Contraintes', 'Risques'), ('Risques', 'Pertes de données'), ('Risques', 'Erreurs de transformation'), ('Temps de latence', 'Erp et datawarehouse'), ('Maintenance', 'Interfaces etl'), ('Entite', 'Personne physique'), ('Entite', 'Field'), ('Entite', 'Base personne'), ('Entite', 'Crm'), ('Entite', 'Membre ecosysteme 1'), ('Field', 'Base operation'), ('Base personne', 'Segmentation des audiences'), ('Crm', 'Applicatif de gestion des relations clients'), ('Crm', 'Centraliser organiser exploiter informations'), ('Crm', 'Emails'), ('Responsables de production', 'Besoins'), ('Responsables de production', 'Problématiques'), ('Julien morel', 'Monsieur'), ('M. morel', 'Difficultés liées au suivi des stocks'), ('M. morel', 'Manque de coordination entre équipes de production'), ('M. morel', 'Suivi centralisé et automatisé des stocks critiques avec alertes préventives'), ('M. morel', 'Meilleure intégration des plannings des équipes dans l’erp'), ('M. martin', 'Ajout module gestion des stocks avancé erp'), ('M. martin', 'Amélioration outils collaboratifs système'), ('M. martin', 'Options'), ('M. martin', 'Mise à disposition d’un portail d’analyse'), ('M. martin', 'Création d’un dashboard'), ('M. martin', 'Intégration d’un système d’alertes'), ('Acces', '[[base operation]]'), ('M. dupont', 'Importance complétude des champs'), ('M. dupont', 'Actions suivantes'), ('M. dupont', 'Mise en place de contrôles automatiques'), ('M. dupont', 'Besoin d’accéder à des données plus complètes'), ('M. dupont', 'Performances des fournisseurs'), ('M. dupont', 'Historique des commandes'), ('Performances des fournisseurs', 'Accès direct'), ('Données complètes', 'Identifier goulets d’étranglement'), ('Dupont', 'Problèmes liés à la situation actuelle'), ('Dupont', 'Amélioration des relations fournisseurs'), ('Dupont', 'Réduction des dépenses'), ('Données de production', 'Certaines périodes'), ('Assurer complétude des données', 'Précision accrue des kpi'), ('Assurer complétude des données', 'Gain de temps pour équipes d’analyse'), ('Organisation', 'Équipes opérationnelles'), ('Complétude des informations', 'Taux d’ouverture des e-mails'), ('Complétude des informations', 'Pertinence des messages'), ('Thomas dupont', 'Besoins d’accès à la base opération'), ('Thomas dupont', 'Gestion des achats')]\n"
     ]
    }
   ],
   "source": [
    "g = graph_index.get_networkx_graph()\n",
    "print(g)\n",
    "print(\"Nodes:\", g.nodes())\n",
    "print(\"Edges:\", g.edges())\n",
    "net = Network(notebook=True, cdn_resources=\"in_line\", directed=True)\n",
    "net.from_nx(g)\n",
    "\n",
    "with open(\"knowledge_graph.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(net.generate_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab94fc0-2080-4869-94a0-b013dc0fbd9d",
   "metadata": {},
   "source": [
    "# (Simple) Query the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c93bdbb-aaa4-4658-aecf-1cd7b5038ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "161e3adf7d724f45b731f79a9aa1771a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "query = \"Je dois lancer un nouveau projet data avec mes données opérationnelles, qui puis-je impliquer, et pour faire quoi ?\"\n",
    "query_engine = simple_index.as_query_engine(\n",
    " include_text=True,\n",
    " response_mode=\"tree_summarize\",\n",
    " embedding_mode=\"hybrid\",\n",
    " similarity_top_k=8,\n",
    ")\n",
    "\n",
    "response = query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2a871b4-70c8-45ed-a8b9-b2aaa8d15a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour lancer un nouveau projet data avec vos données opérationnelles, vous pouvez impliquer plusieurs parties prenantes clés :\n",
       "\n",
       "1. **Mme Laurent** : Elle peut être impliquée pour s'assurer que les données opérationnelles sont complètes et en temps réel, ce qui est crucial pour optimiser les performances et suivre les KPIs locaux. Elle peut aider à identifier les besoins spécifiques en données pour votre projet.\n",
       "\n",
       "2. **M. Dupont** : En tant que directeur de production, il peut jouer un rôle essentiel dans la définition des champs critiques et prioritaires à inclure dans le Datawarehouse. Il peut également aider à mettre en place des contrôles automatiques pour garantir la complétude des données et collaborer avec les équipes IT pour définir les priorités des données critiques.\n",
       "\n",
       "3. **Équipes IT** : Elles seront nécessaires pour la mise en place des processus ETL, la validation des données, et pour assurer la sécurité et la sauvegarde de la base de données. Elles peuvent également organiser des formations pour les équipes opérationnelles.\n",
       "\n",
       "4. **Équipes Opérationnelles** : Elles doivent être formées sur l'importance de la saisie complète des données dans l'ERP et peuvent fournir des retours sur les besoins opérationnels spécifiques.\n",
       "\n",
       "Ensemble, ces parties prenantes peuvent collaborer pour garantir que votre projet data est bien structuré, sécurisé, et répond aux besoins opérationnels.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b099031c-b137-468f-b20c-9c6fab1c4eb1",
   "metadata": {},
   "source": [
    "# (Simple) Query the knowledge graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8948dd2b-acd4-4621-a2d1-b45034a21007",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7423d608ed543fe88a86a96ec479ac7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 4a9725f2-a5cd-47ab-a5cf-c6ff2c957b8e: 5.2 Risques\n",
      "\n",
      "- Panne des interfaces ETL pouvant interrompre les flux de donné...\n",
      "> Querying with idx: 4a9725f2-a5cd-47ab-a5cf-c6ff2c957b8e: 5.2 Risques\n",
      "\n",
      "- Panne des interfaces ETL pouvant interrompre les flux de donné...\n",
      "> Querying with idx: 4a9725f2-a5cd-47ab-a5cf-c6ff2c957b8e: 5.2 Risques\n",
      "\n",
      "- Panne des interfaces ETL pouvant interrompre les flux de donné...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 08b06ef3-6916-491a-a44d-31cf8e4fa62c: ---\n",
      "entite: applicatif\n",
      "feeds: \"[[Datawarehouse]]\"\n",
      "---\n",
      "Ce document détaille le...\n",
      "> Querying with idx: 08b06ef3-6916-491a-a44d-31cf8e4fa62c: ---\n",
      "entite: applicatif\n",
      "feeds: \"[[Datawarehouse]]\"\n",
      "---\n",
      "Ce document détaille le...\n",
      "> Querying with idx: 08b06ef3-6916-491a-a44d-31cf8e4fa62c: ---\n",
      "entite: applicatif\n",
      "feeds: \"[[Datawarehouse]]\"\n",
      "---\n",
      "Ce document détaille le...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 0ef83e4e-956b-4a9a-a07c-c98c95636658: ---\n",
      "entite: base\n",
      "---\n",
      "Ce document a pour objectif de décrire les aspects techn...\n",
      "> Querying with idx: 0ef83e4e-956b-4a9a-a07c-c98c95636658: ---\n",
      "entite: base\n",
      "---\n",
      "Ce document a pour objectif de décrire les aspects techn...\n",
      "> Querying with idx: 0ef83e4e-956b-4a9a-a07c-c98c95636658: ---\n",
      "entite: base\n",
      "---\n",
      "Ce document a pour objectif de décrire les aspects techn...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 6ffd556c-718a-46fb-a6f6-6e30001b1a62: ---\n",
      "entite: base\n",
      "parent: \"[[ERP]]\"\n",
      "---\n",
      "La base de données \"Opérations\" est un...\n",
      "> Querying with idx: 6ffd556c-718a-46fb-a6f6-6e30001b1a62: ---\n",
      "entite: base\n",
      "parent: \"[[ERP]]\"\n",
      "---\n",
      "La base de données \"Opérations\" est un...\n",
      "> Querying with idx: 6ffd556c-718a-46fb-a6f6-6e30001b1a62: ---\n",
      "entite: base\n",
      "parent: \"[[ERP]]\"\n",
      "---\n",
      "La base de données \"Opérations\" est un...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: eb770add-bc93-41ea-b08c-3dad0d299bfb: Prochaines Étapes\n",
      "\n",
      "1. Identification des champs critiques et prioritaires dan...\n",
      "> Querying with idx: eb770add-bc93-41ea-b08c-3dad0d299bfb: Prochaines Étapes\n",
      "\n",
      "1. Identification des champs critiques et prioritaires dan...\n",
      "> Querying with idx: eb770add-bc93-41ea-b08c-3dad0d299bfb: Prochaines Étapes\n",
      "\n",
      "1. Identification des champs critiques et prioritaires dan...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: ced72763-e189-4b56-94ca-e3fe1ed56697: 5.1 Contraintes\n",
      "\n",
      "- Temps de latence entre l’ERP et le Datawarehouse\n",
      "- Complex...\n",
      "> Querying with idx: ced72763-e189-4b56-94ca-e3fe1ed56697: 5.1 Contraintes\n",
      "\n",
      "- Temps de latence entre l’ERP et le Datawarehouse\n",
      "- Complex...\n",
      "> Querying with idx: ced72763-e189-4b56-94ca-e3fe1ed56697: 5.1 Contraintes\n",
      "\n",
      "- Temps de latence entre l’ERP et le Datawarehouse\n",
      "- Complex...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 2d93f7b2-4f8f-4f21-88fc-573dc718e68f: 6. Conclusion\n",
      "\n",
      "L’ERP joue un rôle essentiel dans l’alimentation du Datawareho...\n",
      "> Querying with idx: 2d93f7b2-4f8f-4f21-88fc-573dc718e68f: 6. Conclusion\n",
      "\n",
      "L’ERP joue un rôle essentiel dans l’alimentation du Datawareho...\n",
      "> Querying with idx: 2d93f7b2-4f8f-4f21-88fc-573dc718e68f: 6. Conclusion\n",
      "\n",
      "L’ERP joue un rôle essentiel dans l’alimentation du Datawareho...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: b51fda10-72af-4ac6-bab9-edd7267fd758: Relations avec d'autres Tables\n",
      "\n",
      "- **Table `utilisateurs`** :\n",
      "    - Relation p...\n",
      "> Querying with idx: b51fda10-72af-4ac6-bab9-edd7267fd758: Relations avec d'autres Tables\n",
      "\n",
      "- **Table `utilisateurs`** :\n",
      "    - Relation p...\n",
      "> Querying with idx: b51fda10-72af-4ac6-bab9-edd7267fd758: Relations avec d'autres Tables\n",
      "\n",
      "- **Table `utilisateurs`** :\n",
      "    - Relation p...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 0b6ed73f-12a4-4242-a2df-b61584f5b55a: 3. Contrats d'Interface avec l'ERP\n",
      "> Querying with idx: 0b6ed73f-12a4-4242-a2df-b61584f5b55a: 3. Contrats d'Interface avec l'ERP\n",
      "> Querying with idx: 0b6ed73f-12a4-4242-a2df-b61584f5b55a: 3. Contrats d'Interface avec l'ERP\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 93f4fbfa-1d6a-4ed2-8abb-98aba87976d2: Ajout d'une Opération\n",
      "\n",
      "```sql\n",
      "INSERT INTO operations (nom_op, description_op,...\n",
      "> Querying with idx: 93f4fbfa-1d6a-4ed2-8abb-98aba87976d2: Ajout d'une Opération\n",
      "\n",
      "```sql\n",
      "INSERT INTO operations (nom_op, description_op,...\n",
      "> Querying with idx: 93f4fbfa-1d6a-4ed2-8abb-98aba87976d2: Ajout d'une Opération\n",
      "\n",
      "```sql\n",
      "INSERT INTO operations (nom_op, description_op,...\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "query = \"Je dois lancer un nouveau projet data avec mes données opérationnelles, qui puis-je impliquer, et pour faire quoi ?\"\n",
    "graph_query_engine = graph_index.as_query_engine(\n",
    " include_text=True,\n",
    " response_mode=\"tree_summarize\",\n",
    " embedding_mode=\"hybrid\",\n",
    " similarity_top_k=8,\n",
    ")\n",
    "\n",
    "response = graph_query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ff5382fd-1fc8-4faf-9356-c9bb3e478db5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour lancer un nouveau projet data avec vos données opérationnelles, vous pouvez impliquer plusieurs parties prenantes et définir des rôles spécifiques :\n",
       "\n",
       "1. **Équipes Opérationnelles** : Organisez une formation pour ces équipes afin de les préparer à gérer et analyser les données opérationnelles. Elles joueront un rôle clé dans la collecte et la validation des données.\n",
       "\n",
       "2. **Équipe IT/Technique** : Impliquez-les pour gérer les aspects techniques du Datawarehouse, y compris les flux de données et les transformations nécessaires. Ils seront responsables de la mise en place des règles de validation automatique dans les processus ETL.\n",
       "\n",
       "3. **Responsables de Projet** : Assurez-vous d'avoir un responsable de projet qui peut coordonner les différentes équipes et s'assurer que les objectifs du projet sont atteints. Ils peuvent également gérer les relations entre les opérations et les projets spécifiques.\n",
       "\n",
       "4. **Experts en ERP** : Puisque l'ERP alimente le Datawarehouse, il est crucial d'avoir des experts qui comprennent les modules clés et les flux d'intégration pour garantir la continuité et la fiabilité des échanges de données.\n",
       "\n",
       "Ensemble, ces parties prenantes peuvent collaborer pour assurer le succès du projet en exploitant efficacement les données opérationnelles.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef119d0",
   "metadata": {},
   "source": [
    "# (Simple) Query the onto graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a8db6420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "235c69bcee7c495690e957cab71b9a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "query = \"Je dois lancer un nouveau projet data avec mes données opérationnelles, qui puis-je impliquer, et pour faire quoi ?\"\n",
    "onto_query_engine = onto_index.as_query_engine(\n",
    " include_text=True,\n",
    " similarity_top_k=2,\n",
    ")\n",
    "\n",
    "response = onto_query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "adcd4265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour lancer un nouveau projet data avec vos données opérationnelles, vous pourriez impliquer Mme Sophie Laurent et M. Philippe Martin, qui ont approuvé le compte rendu. Vous pourriez également envisager de réaliser un audit des données disponibles pour identifier les champs pertinents, développer un accès personnalisé avec une interface d'utilisation, et organiser une session de formation pour la prise en main des nouveaux outils.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582274ba",
   "metadata": {},
   "source": [
    "## (Node retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "16db2a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "801e4f07db9244eeb96f11fb7f61fc91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Here are some facts extracted from the provided text:\n",
      "\n",
      "Base Opération -> IMPROVES -> pilotage des activités opérationnelles\n",
      "\n",
      "Prochaines Étapes\n",
      "\n",
      "1. Audit des données disponibles dans la Base Opération et identification des champs pertinents pour Mme Laurent (15 janvier 2025).\n",
      "2. Développement d’un accès personnalisé avec interface d’utilisation (31 janvier 2025).\n",
      "3. Organisation d’une session de formation pour la prise en main des nouveaux outils (15 février 2025).\n",
      "\n",
      "---\n",
      "\n",
      "**Validation** : Le compte rendu a été approuvé par Mme Sophie Laurent et M. Philippe Martin.  \n",
      "**Rédigé par** : [Nom du Rédacteur]\n",
      "Here are some facts extracted from the provided text:\n",
      "\n",
      "date_creation -> HAS_DESCRIPTION -> Date et heure de création de l'opération\n",
      "\n",
      "Création de la Table\n",
      "\n",
      "```sql\n",
      "CREATE TABLE operations (\n",
      "    id_op INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    nom_op VARCHAR(255) NOT NULL,\n",
      "    description_op TEXT,\n",
      "    date_creation TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
      "    statut_op ENUM('en cours', 'terminé', 'annulé'),\n",
      "    responsable_op VARCHAR(255)\n",
      ");\n",
      "```\n",
      "Here are some facts extracted from the provided text:\n",
      "\n",
      "actions -> INCLUDES -> Collaboration étroite entre équipes opérationnelles et IT\n",
      "\n",
      "3. **Suggestions pour l’amélioration**\n",
      "\n",
      "M. Dupont propose les actions suivantes :\n",
      "\n",
      "- Mise en place de contrôles automatiques pour détecter et signaler les champs manquants lors des processus ETL.\n",
      "- Collaboration étroite entre les équipes opérationnelles et IT pour définir les priorités des données critiques.\n",
      "- Formation des équipes terrain sur l’importance de la saisie complète dans l’ERP, notamment pour les données de production et logistiques.\n",
      "Here are some facts extracted from the provided text:\n",
      "\n",
      "statut_op -> HAS_DESCRIPTION -> Statut actuel de l'opération\n",
      "\n",
      "Ajout d'une Opération\n",
      "\n",
      "```sql\n",
      "INSERT INTO operations (nom_op, description_op, statut_op, responsable_op)\n",
      "VALUES ('Lancement Produit', 'Préparation du lancement du nouveau produit', 'en cours', 'Jean Dupont');\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "retriever = onto_index.as_retriever(\n",
    "    include_text=True,  # include source text, default True\n",
    ")\n",
    "\n",
    "nodes = retriever.retrieve(\"Je dois lancer un nouveau projet data avec mes données opérationnelles, qui puis-je impliquer, et pour faire quoi ?\")\n",
    "\n",
    "\n",
    "for node in nodes:\n",
    "    print(node.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a895520-d196-476f-b569-69a67484c120",
   "metadata": {},
   "source": [
    "# Have a real chat with your data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea3764d-a084-4f36-9d8c-3613aa9fd835",
   "metadata": {},
   "source": [
    "## Set up the engines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951e55a2-a9a9-4c4e-89a4-c4dfba55ebe4",
   "metadata": {},
   "source": [
    "### Vector engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1581c90c-cf5a-40d3-81b0-086238068f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ChatMemoryBuffer.from_defaults(token_limit=3900)\n",
    "vector_chat_engine = simple_index.as_chat_engine(\n",
    "    chat_mode=\"condense_plus_context\",\n",
    "    memory=memory,\n",
    "    llm=llm,\n",
    "    context_prompt=(\n",
    "        \"Tu es un consultant spécialisé en stratégie et gouvernance des données.\"\n",
    "        \"Pour des idées de projets, tu vas proposer une stratégie et une gouvernance pour la mettre en oeuvre\"\n",
    "        \"Tu feras attention à mettre en avant le Return On Investment (ROI) du projet proposé\"\n",
    "    ),\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315a1c22-111b-4793-8a3d-bd3eae7e3ec7",
   "metadata": {},
   "source": [
    "### Graph engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "98b73cc2-0588-4b96-9aa2-1dfaf4cadb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ChatMemoryBuffer.from_defaults(token_limit=3900)\n",
    "graph_chat_engine = graph_index.as_chat_engine(\n",
    "    chat_mode=\"condense_plus_context\",\n",
    "    memory=memory,\n",
    "    llm=llm,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6897ec22",
   "metadata": {},
   "source": [
    "### Onto engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54d04e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#onto_chat_engine = onto_index.query_engine(\n",
    "#    chat_mode=\"condense_plus_context\",\n",
    "#    llm=llm\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3e0a08-f6ff-4ee6-a165-9b9fd90621fa",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "12804e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_chat_engine.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "709a37e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ChatMemoryBuffer.from_defaults(token_limit=3900)\n",
    "graph_chat_engine = graph_index.as_chat_engine(\n",
    "    chat_mode=\"condense_plus_context\",\n",
    "    memory=memory,\n",
    "    llm=llm,\n",
    "    context_prompt=(\n",
    "        \"Tu es un consultant spécialisé en stratégie et gouvernance des données.\"\n",
    "        \"Tu cites en priorité les métiers, les bases de données ou les champs de données présents dans ta base de connaissance.\"\n",
    "        \"Pour des idées de projets, tu vas proposer une stratégie et une gouvernance pour la mettre en oeuvre\"\n",
    "        \"Tu feras attention à mettre en avant le Return On Investment (ROI) du projet proposé\"\n",
    "    ),\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "da3e3ebf-18dc-4bdc-87dc-58d0227e9c18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.chat_engine.condense_plus_context:Condensed question: D'après tes connaissances et ta vision du monde, réponds moi aussi précisément que possible.Je dois lancer un nouveau projet data avec mes données opérationnelles, qui puis-je impliquer, et pour faire quoi ?\n",
      "Condensed question: D'après tes connaissances et ta vision du monde, réponds moi aussi précisément que possible.Je dois lancer un nouveau projet data avec mes données opérationnelles, qui puis-je impliquer, et pour faire quoi ?\n",
      "Condensed question: D'après tes connaissances et ta vision du monde, réponds moi aussi précisément que possible.Je dois lancer un nouveau projet data avec mes données opérationnelles, qui puis-je impliquer, et pour faire quoi ?\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f40bede9ae9d436d8a01468310134496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 6ffd556c-718a-46fb-a6f6-6e30001b1a62: ---\n",
      "entite: base\n",
      "parent: \"[[ERP]]\"\n",
      "---\n",
      "La base de données \"Opérations\" est un...\n",
      "> Querying with idx: 6ffd556c-718a-46fb-a6f6-6e30001b1a62: ---\n",
      "entite: base\n",
      "parent: \"[[ERP]]\"\n",
      "---\n",
      "La base de données \"Opérations\" est un...\n",
      "> Querying with idx: 6ffd556c-718a-46fb-a6f6-6e30001b1a62: ---\n",
      "entite: base\n",
      "parent: \"[[ERP]]\"\n",
      "---\n",
      "La base de données \"Opérations\" est un...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: b51fda10-72af-4ac6-bab9-edd7267fd758: Relations avec d'autres Tables\n",
      "\n",
      "- **Table `utilisateurs`** :\n",
      "    - Relation p...\n",
      "> Querying with idx: b51fda10-72af-4ac6-bab9-edd7267fd758: Relations avec d'autres Tables\n",
      "\n",
      "- **Table `utilisateurs`** :\n",
      "    - Relation p...\n",
      "> Querying with idx: b51fda10-72af-4ac6-bab9-edd7267fd758: Relations avec d'autres Tables\n",
      "\n",
      "- **Table `utilisateurs`** :\n",
      "    - Relation p...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 93f4fbfa-1d6a-4ed2-8abb-98aba87976d2: Ajout d'une Opération\n",
      "\n",
      "```sql\n",
      "INSERT INTO operations (nom_op, description_op,...\n",
      "> Querying with idx: 93f4fbfa-1d6a-4ed2-8abb-98aba87976d2: Ajout d'une Opération\n",
      "\n",
      "```sql\n",
      "INSERT INTO operations (nom_op, description_op,...\n",
      "> Querying with idx: 93f4fbfa-1d6a-4ed2-8abb-98aba87976d2: Ajout d'une Opération\n",
      "\n",
      "```sql\n",
      "INSERT INTO operations (nom_op, description_op,...\n"
     ]
    }
   ],
   "source": [
    "response_stream = graph_chat_engine.stream_chat(\"\"\"D'après tes connaissances et ta vision du monde, réponds moi aussi précisément que possible.Je dois lancer un nouveau projet data avec mes données opérationnelles, qui puis-je impliquer, et pour faire quoi ?\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "91ebf21f-1990-4a4d-9c9a-868872f03042",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Lancer un projet data avec vos données opérationnelles est une initiative stratégique qui peut apporter une valeur significative à votre organisation. Voici une stratégie et une gouvernance pour mettre en œuvre ce projet, en mettant l'accent sur le ROI :\n",
      "\n",
      "### 1. **Constitution de l'équipe projet**\n",
      "\n",
      "#### a. **Responsable de projet (Project Manager)**\n",
      "   - **Rôle** : Superviser l'ensemble du projet, coordonner les équipes, gérer le budget et le calendrier.\n",
      "   - **ROI** : Assure que le projet est livré à temps et dans les limites du budget, maximisant ainsi l'efficacité des ressources.\n",
      "\n",
      "#### b. **Data Scientist/Analyst**\n",
      "   - **Rôle** : Analyser les données opérationnelles pour extraire des insights exploitables.\n",
      "   - **ROI** : Identifie les opportunités d'optimisation des processus et de réduction des coûts.\n",
      "\n",
      "#### c. **Data Engineer**\n",
      "   - **Rôle** : Concevoir et maintenir l'infrastructure de données, assurer la qualité et l'intégrité des données.\n",
      "   - **ROI** : Garantit que les données sont fiables et accessibles, réduisant ainsi les inefficacités opérationnelles.\n",
      "\n",
      "#### d. **Expert Métier (Business Analyst)**\n",
      "   - **Rôle** : Traduire les besoins métiers en exigences techniques, assurer l'alignement avec les objectifs stratégiques.\n",
      "   - **ROI** : Assure que les solutions développées répondent aux besoins réels de l'entreprise, augmentant ainsi l'adoption et l'impact.\n",
      "\n",
      "#### e. **Responsable de la Gouvernance des Données**\n",
      "   - **Rôle** : Mettre en place des politiques de gestion des données, assurer la conformité réglementaire.\n",
      "   - **ROI** : Réduit les risques liés à la non-conformité et améliore la confiance dans les données.\n",
      "\n",
      "#### f. **IT Support**\n",
      "   - **Rôle** : Assurer le support technique et la maintenance des systèmes.\n",
      "   - **ROI** : Minimise les interruptions de service, garantissant une disponibilité continue des données.\n",
      "\n",
      "### 2. **Stratégie de mise en œuvre**\n",
      "\n",
      "#### a. **Évaluation des besoins et des opportunités**\n",
      "   - **Action** : Effectuer une analyse des besoins pour identifier les domaines où les données peuvent apporter le plus de valeur.\n",
      "   - **ROI** : Priorise les initiatives à fort impact, maximisant ainsi le retour sur investissement.\n",
      "\n",
      "#### b. **Développement d'une feuille de route**\n",
      "   - **Action** : Créer un plan détaillé avec des jalons clairs et des indicateurs de performance clés (KPI).\n",
      "   - **ROI** : Permet de suivre les progrès et d'ajuster les stratégies pour optimiser les résultats.\n",
      "\n",
      "#### c. **Mise en œuvre de solutions technologiques**\n",
      "   - **Action** : Déployer des outils d'analyse de données et de visualisation pour faciliter l'accès aux insights.\n",
      "   - **ROI** : Améliore la prise de décision basée sur les données, augmentant l'efficacité opérationnelle.\n",
      "\n",
      "#### d. **Formation et adoption**\n",
      "   - **Action** : Former les employés à l'utilisation des nouvelles solutions et promouvoir une culture axée sur les données.\n",
      "   - **ROI** : Augmente l'adoption des solutions et maximise leur impact sur l'organisation.\n",
      "\n",
      "### 3. **Gouvernance des données**\n",
      "\n",
      "#### a. **Politiques de gestion des données**\n",
      "   - **Action** : Établir des politiques pour la collecte, le stockage, et l'utilisation des données.\n",
      "   - **ROI** : Assure la qualité et la sécurité des données, réduisant les risques et les coûts associés aux erreurs de données.\n",
      "\n",
      "#### b. **Conformité et sécurité**\n",
      "   - **Action** : Mettre en place des mesures de sécurité pour protéger les données sensibles et assurer la conformité avec les réglementations.\n",
      "   - **ROI** : Évite les amendes et les pertes de réputation liées aux violations de données.\n",
      "\n",
      "En impliquant les bonnes personnes et en suivant une stratégie bien définie, vous pouvez maximiser le ROI de votre projet data en exploitant pleinement le potentiel de vos données opérationnelles."
     ]
    }
   ],
   "source": [
    "generate = response_stream.print_response_stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5a056a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>None</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{generate}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6660a81e-ad67-4d44-a86d-0ad7b77f626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_modele = \"\"\" \n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9c0e462e-d3ee-463a-8d49-f09dc2396b8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.core.chat_engine.condense_plus_context:Condensed question: D'après tes connaissances et ta vision du monde, quel serait le schéma de données idéal pour un projet data utilisant des données opérationnelles, en utilisant le schéma de données standard Frictionless pour le décrire ? Peux-tu imiter le style d'écriture de la {section_modele} ?\n",
      "Condensed question: D'après tes connaissances et ta vision du monde, quel serait le schéma de données idéal pour un projet data utilisant des données opérationnelles, en utilisant le schéma de données standard Frictionless pour le décrire ? Peux-tu imiter le style d'écriture de la {section_modele} ?\n",
      "Condensed question: D'après tes connaissances et ta vision du monde, quel serait le schéma de données idéal pour un projet data utilisant des données opérationnelles, en utilisant le schéma de données standard Frictionless pour le décrire ? Peux-tu imiter le style d'écriture de la {section_modele} ?\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "819b703fbfab4291b843d97de3b6a41a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 0ef83e4e-956b-4a9a-a07c-c98c95636658: ---\n",
      "entite: base\n",
      "---\n",
      "Ce document a pour objectif de décrire les aspects techn...\n",
      "> Querying with idx: 0ef83e4e-956b-4a9a-a07c-c98c95636658: ---\n",
      "entite: base\n",
      "---\n",
      "Ce document a pour objectif de décrire les aspects techn...\n",
      "> Querying with idx: 0ef83e4e-956b-4a9a-a07c-c98c95636658: ---\n",
      "entite: base\n",
      "---\n",
      "Ce document a pour objectif de décrire les aspects techn...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: b8f1fe18-2d23-4fc9-ae6c-0a9ccabf3cdd: Schéma de la Base de Données\n",
      "> Querying with idx: b8f1fe18-2d23-4fc9-ae6c-0a9ccabf3cdd: Schéma de la Base de Données\n",
      "> Querying with idx: b8f1fe18-2d23-4fc9-ae6c-0a9ccabf3cdd: Schéma de la Base de Données\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 08b06ef3-6916-491a-a44d-31cf8e4fa62c: ---\n",
      "entite: applicatif\n",
      "feeds: \"[[Datawarehouse]]\"\n",
      "---\n",
      "Ce document détaille le...\n",
      "> Querying with idx: 08b06ef3-6916-491a-a44d-31cf8e4fa62c: ---\n",
      "entite: applicatif\n",
      "feeds: \"[[Datawarehouse]]\"\n",
      "---\n",
      "Ce document détaille le...\n",
      "> Querying with idx: 08b06ef3-6916-491a-a44d-31cf8e4fa62c: ---\n",
      "entite: applicatif\n",
      "feeds: \"[[Datawarehouse]]\"\n",
      "---\n",
      "Ce document détaille le...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 0f66ddb9-5a5e-4891-af47-7904172d3869: 2.3 Architecture\n",
      "\n",
      "- **Base de données** : Oracle Database 19c\n",
      "- **Langage de ...\n",
      "> Querying with idx: 0f66ddb9-5a5e-4891-af47-7904172d3869: 2.3 Architecture\n",
      "\n",
      "- **Base de données** : Oracle Database 19c\n",
      "- **Langage de ...\n",
      "> Querying with idx: 0f66ddb9-5a5e-4891-af47-7904172d3869: 2.3 Architecture\n",
      "\n",
      "- **Base de données** : Oracle Database 19c\n",
      "- **Langage de ...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: a83449a2-12a5-48a5-8ad6-0a20b8c9bb92: 2.2 Architecture\n",
      "\n",
      "- **Base de données** : PostgreSQL 14\n",
      "- **Structure** : Mod...\n",
      "> Querying with idx: a83449a2-12a5-48a5-8ad6-0a20b8c9bb92: 2.2 Architecture\n",
      "\n",
      "- **Base de données** : PostgreSQL 14\n",
      "- **Structure** : Mod...\n",
      "> Querying with idx: a83449a2-12a5-48a5-8ad6-0a20b8c9bb92: 2.2 Architecture\n",
      "\n",
      "- **Base de données** : PostgreSQL 14\n",
      "- **Structure** : Mod...\n"
     ]
    }
   ],
   "source": [
    "response_stream = graph_chat_engine.stream_chat(\"\"\"D'après tes connaissances et ta vision du monde, réponds moi aussi précisément que possible, quel serait le schéma de données idéal pour ce projet. Utilise le schéma de données standard Frictionless pour le décrire. Imite le style d'écriture de la {section_modele}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c86075ee-12c8-4b97-8b51-0c717fc4b1d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Pour concevoir un schéma de données idéal pour votre projet en utilisant le standard Frictionless, il est essentiel de structurer vos données de manière à maximiser leur utilité et leur interopérabilité. Voici un exemple de schéma de données en utilisant le format Frictionless, qui est un standard ouvert pour la publication de données tabulaires :\n",
      "\n",
      "### {section_modele}\n",
      "\n",
      "#### Nom du schéma : **OpérationsDataSchema**\n",
      "\n",
      "#### Description : \n",
      "Ce schéma de données est conçu pour structurer les données opérationnelles de l'organisation, facilitant ainsi l'analyse et l'extraction d'insights pour améliorer l'efficacité et la prise de décision.\n",
      "\n",
      "#### Ressources :\n",
      "\n",
      "1. **Table : Transactions**\n",
      "\n",
      "   - **Description** : Contient les enregistrements de toutes les transactions opérationnelles.\n",
      "   - **Colonnes** :\n",
      "     - `transaction_id` : Identifiant unique de la transaction (Type : `integer`, Obligatoire : `true`)\n",
      "     - `date` : Date de la transaction (Type : `date`, Format : `YYYY-MM-DD`, Obligatoire : `true`)\n",
      "     - `amount` : Montant de la transaction (Type : `number`, Obligatoire : `true`)\n",
      "     - `currency` : Devise utilisée (Type : `string`, Longueur maximale : `3`, Obligatoire : `true`)\n",
      "     - `customer_id` : Identifiant du client (Type : `integer`, Obligatoire : `true`)\n",
      "     - `product_id` : Identifiant du produit (Type : `integer`, Obligatoire : `true`)\n",
      "\n",
      "2. **Table : Clients**\n",
      "\n",
      "   - **Description** : Détails des clients impliqués dans les transactions.\n",
      "   - **Colonnes** :\n",
      "     - `customer_id` : Identifiant unique du client (Type : `integer`, Obligatoire : `true`)\n",
      "     - `name` : Nom du client (Type : `string`, Longueur maximale : `100`, Obligatoire : `true`)\n",
      "     - `email` : Adresse e-mail du client (Type : `string`, Format : `email`, Obligatoire : `false`)\n",
      "     - `phone` : Numéro de téléphone du client (Type : `string`, Longueur maximale : `15`, Obligatoire : `false`)\n",
      "     - `join_date` : Date d'inscription du client (Type : `date`, Format : `YYYY-MM-DD`, Obligatoire : `true`)\n",
      "\n",
      "3. **Table : Produits**\n",
      "\n",
      "   - **Description** : Informations sur les produits disponibles pour les transactions.\n",
      "   - **Colonnes** :\n",
      "     - `product_id` : Identifiant unique du produit (Type : `integer`, Obligatoire : `true`)\n",
      "     - `name` : Nom du produit (Type : `string`, Longueur maximale : `100`, Obligatoire : `true`)\n",
      "     - `category` : Catégorie du produit (Type : `string`, Longueur maximale : `50`, Obligatoire : `true`)\n",
      "     - `price` : Prix du produit (Type : `number`, Obligatoire : `true`)\n",
      "     - `stock_quantity` : Quantité en stock (Type : `integer`, Obligatoire : `true`)\n",
      "\n",
      "#### Relations :\n",
      "\n",
      "- **Transactions** est lié à **Clients** par `customer_id`.\n",
      "- **Transactions** est lié à **Produits** par `product_id`.\n",
      "\n",
      "#### Métadonnées :\n",
      "\n",
      "- **Version** : 1.0\n",
      "- **Auteur** : [Nom de l'auteur]\n",
      "- **Licence** : [Type de licence, par exemple, CC BY 4.0]\n",
      "- **Sources** : [Sources des données, si applicable]\n",
      "\n",
      "### Avantages du schéma :\n",
      "\n",
      "- **Interopérabilité** : Le format Frictionless facilite l'échange de données entre différents systèmes et outils d'analyse.\n",
      "- **Clarté** : Une structure claire et bien définie permet une compréhension facile des données par toutes les parties prenantes.\n",
      "- **Scalabilité** : Le schéma peut être facilement étendu pour inclure de nouvelles tables ou colonnes à mesure que les besoins évoluent.\n",
      "\n",
      "En adoptant ce schéma de données, vous assurez une base solide pour l'analyse de vos données opérationnelles, ce qui peut conduire à des améliorations significatives en termes de performance et de prise de décision."
     ]
    }
   ],
   "source": [
    "generate = response_stream.print_response_stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ffb78d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>None</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{generate}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f74a302-bb28-4bf8-9103-1f62750a5fc0",
   "metadata": {},
   "source": [
    "## Sum-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d81f7480-9d62-4952-948e-19e089d9da9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = memory.get_all()\n",
    "\n",
    "# Assuming chat_history is available and contains your messages\n",
    "assistant_messages = [\n",
    "    message.content \n",
    "    for message in chat_history \n",
    "    if message.role == MessageRole.ASSISTANT  # Compare with the enum directly\n",
    "]\n",
    "\n",
    "\n",
    "output_filename = r\"/Users/arthursarazin/Documents/coreandgraphs/graphandgovern/output116n87e.md\"\n",
    "# Write to a Markdown file\n",
    "with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    for msg in assistant_messages:\n",
    "        f.write(msg + \"\\n\\n\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
