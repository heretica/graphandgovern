{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "45492c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (0.12.8)\n",
      "Requirement already satisfied: llama-index-readers-obsidian in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (0.4.0)\n",
      "Requirement already satisfied: ipywidgets in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (8.1.5)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (4.67.1)\n",
      "Requirement already satisfied: ipython in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from -r requirements.txt (line 5)) (8.16.0)\n",
      "Requirement already satisfied: huggingface-hub in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (0.27.0)\n",
      "Requirement already satisfied: openai in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (1.58.1)\n",
      "Requirement already satisfied: pyyaml in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (6.0.2)\n",
      "Requirement already satisfied: llama-index-llms-ollama in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (0.5.0)\n",
      "Requirement already satisfied: llama-index-embeddings-ollama in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (0.5.0)\n",
      "Requirement already satisfied: llama-index-embeddings-huggingface in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (0.4.0)\n",
      "Requirement already satisfied: ipykernel in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from -r requirements.txt (line 12)) (6.25.2)\n",
      "Requirement already satisfied: pyvis in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (0.3.2)\n",
      "Requirement already satisfied: python-dotenv in /opt/homebrew/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (1.0.1)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.8 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.12.8)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.3.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.6.3)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.3.12)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.3.1)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.3.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in /opt/homebrew/lib/python3.10/site-packages (from llama-index->-r requirements.txt (line 1)) (3.9.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipywidgets->-r requirements.txt (line 3)) (0.1.4)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipywidgets->-r requirements.txt (line 3)) (5.10.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /opt/homebrew/lib/python3.10/site-packages (from ipywidgets->-r requirements.txt (line 3)) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /opt/homebrew/lib/python3.10/site-packages (from ipywidgets->-r requirements.txt (line 3)) (3.0.13)\n",
      "Requirement already satisfied: backcall in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (0.2.0)\n",
      "Requirement already satisfied: decorator in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (0.19.0)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (2.16.1)\n",
      "Requirement already satisfied: stack-data in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (0.6.2)\n",
      "Requirement already satisfied: exceptiongroup in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (1.1.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (4.8.0)\n",
      "Requirement already satisfied: appnope in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (0.1.3)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub->-r requirements.txt (line 6)) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub->-r requirements.txt (line 6)) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from huggingface-hub->-r requirements.txt (line 6)) (23.1)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub->-r requirements.txt (line 6)) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub->-r requirements.txt (line 6)) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/homebrew/lib/python3.10/site-packages (from openai->-r requirements.txt (line 7)) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/lib/python3.10/site-packages (from openai->-r requirements.txt (line 7)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/lib/python3.10/site-packages (from openai->-r requirements.txt (line 7)) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from openai->-r requirements.txt (line 7)) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/homebrew/lib/python3.10/site-packages (from openai->-r requirements.txt (line 7)) (2.10.4)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/lib/python3.10/site-packages (from openai->-r requirements.txt (line 7)) (1.3.1)\n",
      "Requirement already satisfied: ollama>=0.4.3 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-llms-ollama->-r requirements.txt (line 9)) (0.4.4)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.1 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (3.3.1)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipykernel->-r requirements.txt (line 12)) (1.8.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipykernel->-r requirements.txt (line 12)) (8.3.1)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipykernel->-r requirements.txt (line 12)) (5.3.2)\n",
      "Requirement already satisfied: nest-asyncio in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipykernel->-r requirements.txt (line 12)) (1.5.8)\n",
      "Requirement already satisfied: psutil in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipykernel->-r requirements.txt (line 12)) (5.9.5)\n",
      "Requirement already satisfied: pyzmq>=20 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipykernel->-r requirements.txt (line 12)) (25.1.1)\n",
      "Requirement already satisfied: tornado>=6.1 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from ipykernel->-r requirements.txt (line 12)) (6.3.3)\n",
      "Requirement already satisfied: jinja2>=2.9.6 in /opt/homebrew/lib/python3.10/site-packages (from pyvis->-r requirements.txt (line 13)) (3.1.5)\n",
      "Requirement already satisfied: jsonpickle>=1.4.1 in /opt/homebrew/lib/python3.10/site-packages (from pyvis->-r requirements.txt (line 13)) (4.0.1)\n",
      "Requirement already satisfied: networkx>=1.11 in /opt/homebrew/lib/python3.10/site-packages (from pyvis->-r requirements.txt (line 13)) (3.4.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/homebrew/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 7)) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 7)) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 7)) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 7)) (0.14.0)\n",
      "Requirement already satisfied: aiohttp in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (3.11.11)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from jedi>=0.16->ipython->-r requirements.txt (line 5)) (0.8.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.10/site-packages (from jinja2>=2.9.6->pyvis->-r requirements.txt (line 13)) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 12)) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 12)) (3.10.0)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /opt/homebrew/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (2.0.36)\n",
      "Requirement already satisfied: dataclasses-json in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (10.0.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (0.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: llama-cloud>=0.1.5 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index->-r requirements.txt (line 1)) (0.1.7)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (4.12.3)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (2.2.1)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (5.1.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 1)) (0.5.18)\n",
      "Requirement already satisfied: click in /opt/homebrew/lib/python3.10/site-packages (from nltk>3.8.1->llama-index->-r requirements.txt (line 1)) (8.1.8)\n",
      "Requirement already satisfied: joblib in /opt/homebrew/lib/python3.10/site-packages (from nltk>3.8.1->llama-index->-r requirements.txt (line 1)) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/homebrew/lib/python3.10/site-packages (from nltk>3.8.1->llama-index->-r requirements.txt (line 1)) (2024.11.6)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from pexpect>4.3->ipython->-r requirements.txt (line 5)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython->-r requirements.txt (line 5)) (0.2.7)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/homebrew/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 7)) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.10/site-packages (from requests->huggingface-hub->-r requirements.txt (line 6)) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.10/site-packages (from requests->huggingface-hub->-r requirements.txt (line 6)) (2.3.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (4.47.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.6.0)\n",
      "Requirement already satisfied: scipy in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.14.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from stack-data->ipython->-r requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from stack-data->ipython->-r requirements.txt (line 5)) (2.4.0)\n",
      "Requirement already satisfied: pure-eval in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from stack-data->ipython->-r requirements.txt (line 5)) (0.2.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.18.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/arthursarazin/Library/Python/3.10/lib/python/site-packages (from asttokens>=2.1.0->stack-data->ipython->-r requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/homebrew/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (2.6)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/homebrew/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (3.1.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/homebrew/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/homebrew/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/homebrew/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (0.4.5)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/homebrew/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/homebrew/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (3.23.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.10/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/lib/python3.10/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (3.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "614fc4e2-0e04-49b0-bf7c-05efee48933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.obsidian import ObsidianReader\n",
    "from llama_index.core.memory.chat_memory_buffer import MessageRole\n",
    "from llama_index.core import SimpleDirectoryReader, KnowledgeGraphIndex, VectorStoreIndex\n",
    "from llama_index.core.graph_stores import SimpleGraphStore\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "from llama_index.core import Document, PropertyGraphIndex\n",
    "from llama_index.core.storage.index_store import SimpleIndexStore\n",
    "from llama_index.core.vector_stores import SimpleVectorStore\n",
    "from llama_index.core import Settings\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import os\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "import logging\n",
    "import sys\n",
    "import ipywidgets as widgets\n",
    "import json\n",
    "from llama_index.core.callbacks import CallbackManager\n",
    "from llama_index.core.callbacks import LlamaDebugHandler\n",
    "from llama_index.core import ServiceContext\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.retrievers import KnowledgeGraphRAGRetriever\n",
    "from llama_index.core.indices.property_graph import (\n",
    "    SimpleLLMPathExtractor,\n",
    "    SchemaLLMPathExtractor,\n",
    "    DynamicLLMPathExtractor,\n",
    ")\n",
    "import yaml\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b5e9f925-0bd9-406c-a41d-8be268260b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    load_index_from_storage,\n",
    "    load_indices_from_storage,\n",
    "    load_graph_from_storage,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8291822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "17dd9f9d-7e21-49ef-9a01-d8b0dd7fdc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9954a1",
   "metadata": {},
   "source": [
    "# Set LLM (OpenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3a66b699",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  # Charge les variables depuis le fichier .env\n",
    "api_key = os.getenv(\"OPENAI_API_KEY_UP\")\n",
    "# Modifier ou ajouter une variable d'environnement\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6f9e96ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, model=\"gpt-4o\", max_tokens=3000)\n",
    "Settings.llm = llm\n",
    "Settings.chunk_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512d7bc2",
   "metadata": {},
   "source": [
    "# Set local LLM for embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "aa4bc549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "INFO:sentence_transformers.SentenceTransformer:2 prompts are loaded, with the keys: ['query', 'text']\n",
      "2 prompts are loaded, with the keys: ['query', 'text']\n",
      "2 prompts are loaded, with the keys: ['query', 'text']\n",
      "2 prompts are loaded, with the keys: ['query', 'text']\n"
     ]
    }
   ],
   "source": [
    "# bge-base embedding model\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "#Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7a4b82",
   "metadata": {},
   "source": [
    "# Set LLM for chat  (Local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d46a1ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm = Ollama(model=\"tinyllama\", request_timeout=120.0)\n",
    "#Settings.llm = llm\n",
    "#Settings.chunk_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bc9d70",
   "metadata": {},
   "source": [
    "# Test LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d810955e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "assistant: As a data governance consultant, I don't have personal preferences or feelings, but I can certainly highlight some popular data tools that are widely appreciated in the industry for their capabilities. Tools like Collibra, Informatica, and Alation are often favored for their robust data governance features, including data cataloging, data lineage, and compliance management. Each tool has its strengths, and the best choice often depends on the specific needs and context of an organization.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"You are a data governance consultant\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"What's your favorite data tool ?\"),\n",
    "]\n",
    "resp = llm.chat(messages)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47252b4e-eb58-453c-9e7d-bab5286ee296",
   "metadata": {},
   "source": [
    "# Load storage contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1e8019-e150-4a60-b59d-cac7a4aebcba",
   "metadata": {},
   "source": [
    "## Load vector storage context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "42c55a04-2b21-4c05-96fb-f0f9ce26bb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_storage_context = StorageContext.from_defaults(\n",
    "    docstore=SimpleDocumentStore.from_persist_dir(persist_dir=\"vector\"),\n",
    "    vector_store=SimpleVectorStore.from_persist_dir(\n",
    "        persist_dir=\"vector\"\n",
    "    ),\n",
    "    index_store=SimpleIndexStore.from_persist_dir(persist_dir=\"vector\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564b951a-9776-46da-9309-142acfc3f1dd",
   "metadata": {},
   "source": [
    "## Load knowledge graph storage context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a086ef48-3be3-4a12-b158-4ed50aa2b917",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_storage_context = StorageContext.from_defaults(\n",
    "    docstore=SimpleDocumentStore.from_persist_dir(persist_dir=\"knowledge_graph\"),\n",
    "    graph_store=SimpleGraphStore.from_persist_dir(\n",
    "        persist_dir=\"knowledge_graph\"\n",
    "    ),\n",
    "    index_store=SimpleIndexStore.from_persist_dir(persist_dir=\"knowledge_graph\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28317dfb",
   "metadata": {},
   "source": [
    "## Load onto graph storage context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "db73d4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "onto_storage_context = StorageContext.from_defaults(\n",
    "    docstore=SimpleDocumentStore.from_persist_dir(persist_dir=\"onto_graph\"),\n",
    "    graph_store=SimpleGraphStore.from_persist_dir(\n",
    "        persist_dir=\"onto_graph\"\n",
    "    ),\n",
    "    index_store=SimpleIndexStore.from_persist_dir(persist_dir=\"onto_graph\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6d278b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StorageContext(docstore=<llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore object at 0x163503c40>, index_store=<llama_index.core.storage.index_store.simple_index_store.SimpleIndexStore object at 0x1635019c0>, vector_stores={'default': SimpleVectorStore(stores_text=False, is_embedding_query=True, data=SimpleVectorStoreData(embedding_dict={}, text_id_to_ref_doc_id={}, metadata_dict={})), 'image': SimpleVectorStore(stores_text=False, is_embedding_query=True, data=SimpleVectorStoreData(embedding_dict={}, text_id_to_ref_doc_id={}, metadata_dict={}))}, graph_store=<llama_index.core.graph_stores.simple.SimpleGraphStore object at 0x163502a70>, property_graph_store=None)\n"
     ]
    }
   ],
   "source": [
    "print(onto_storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261c3f5b-f0fa-4e10-85fd-9ff7642de428",
   "metadata": {},
   "source": [
    "# Load index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb3e85a-8fca-4138-9ff9-fca4637a47e2",
   "metadata": {},
   "source": [
    "## Load vector index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "68274006-61a7-42d7-9556-6ddae87d2b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.loading:Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n"
     ]
    }
   ],
   "source": [
    "simple_index = load_index_from_storage(vector_storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cdab09-2c63-4e23-9ca3-79102db74cf0",
   "metadata": {},
   "source": [
    "### Set retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a6c3e925-229f-4636-a7b7-73687a3aa7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_query_engine = simple_index.as_query_engine(\n",
    " include_text=True,\n",
    " response_mode=\"tree_summarize\",\n",
    " embedding_mode=\"hybrid\",\n",
    " similarity_top_k=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7b32a3",
   "metadata": {},
   "source": [
    "### Test retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "887f57e4-8bc9-440b-a84c-0080cbd412e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f57f96e483794407b16b4a1f22a2ff77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "simple_rag_retriever = simple_index.as_retriever(\n",
    "    retriever_mode=\"hybrid\",  # or \"embedding\" or \"hybrid\"\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "response = simple_query_engine.query(\n",
    "    \"Je dois lancer un nouveau projet data avec mes données opérationnelles, qui puis-je impliquer, et pour faire quoi ?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f014fd60-81a4-4b7f-aef9-f545402e0fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour lancer un nouveau projet data avec vos données opérationnelles, vous pouvez impliquer plusieurs personnes et équipes clés :\n",
       "\n",
       "1. **Mme Laurent** : Elle a exprimé le besoin d'accéder à des données plus complètes et en temps réel. Vous pouvez l'impliquer pour définir les besoins en données et les indicateurs clés de performance (KPIs) à suivre.\n",
       "\n",
       "2. **M. Dupont** : En tant que Directeur de la production, il peut être crucial pour assurer la complétude des champs dans le Datawarehouse. Il peut également aider à identifier les champs critiques et prioritaires, et à mettre en place des contrôles automatiques pour garantir la qualité des données.\n",
       "\n",
       "3. **Équipes IT** : Elles seront essentielles pour la mise en place des processus ETL, la validation des données, et la gestion de la sécurité et des sauvegardes de la base de données.\n",
       "\n",
       "4. **Équipes Opérationnelles** : Elles devraient être formées pour comprendre l'importance de la saisie complète des données et pour collaborer avec les équipes IT afin de définir les priorités des données critiques.\n",
       "\n",
       "5. **Responsable de la Base Opération** : Cette personne peut aider à fournir une documentation claire et détaillée de la base de données \"Opérations\" pour garantir une compréhension commune et faciliter son utilisation.\n",
       "\n",
       "Ensemble, ces acteurs peuvent contribuer à la réussite de votre projet en assurant la qualité, la complétude, et l'accessibilité des données opérationnelles.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4242ad8d-20fb-4126-9380-4d51c7e3fa32",
   "metadata": {},
   "source": [
    "## Load graph index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "75e3c260-c349-43f0-b54c-6dac7a12586f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.loading:Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n"
     ]
    }
   ],
   "source": [
    "graph_index = load_index_from_storage(graph_storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "81c1e83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = graph_index.get_networkx_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8424ed30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in the knowledge graph: 87\n"
     ]
    }
   ],
   "source": [
    "# Count the number of nodes\n",
    "num_nodes = len(nx_graph.edges())\n",
    "\n",
    "print(f\"Number of nodes in the knowledge graph: {num_nodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0388bce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 116 nodes and 87 edges\n",
      "Nodes: ['Document', 'Aspects techniques du datawarehouse', 'Spécifications des flux de données', 'Caractéristiques techniques', 'Description', 'Datawarehouse', 'Réservoir central', 'Données consolidées', 'Élément crucial', 'Fiabilité', 'Postgresql 14', 'Base de données', 'Modèle en étoile', 'Structure', 'Directeur de la production', 'Accès', 'Politiques strictes', 'Administrateurs système', 'Indirect', 'Contrats', 'Erp', 'Système central de gestion', 'Données relatives à', 'Visibilité en temps réel', 'Interfaces', 'Transfert des données', 'Informations précises et à jour', 'Interface', 'Etl', 'Outil', 'Talend data integration', 'Source', 'Erp (sap', 'Destination', 'Tables de faits et dimensions du datawarehouse', 'Planification', 'Ordonnanceur cron', 'Alertes', \"Emails et logs en cas d'échec\", 'Gestion', 'Données', 'Fragmentées', 'Validation', 'Contrôles sur les types et les règles métier', 'Reporting', 'Tableau de bord sur les échecs de flux', 'Rétention', '7 ans', 'Archivage', 'Compression et stockage sur un serveur sftp', 'Contraintes', 'Risques', 'Pertes de données', 'Erreurs de transformation', 'Temps de latence', 'Erp et datawarehouse', 'Maintenance', 'Interfaces etl', 'Entite', 'Personne physique', 'Field', 'Base personne', 'Crm', 'Membre ecosysteme 1', 'Responsables de production', 'Besoins', 'Problématiques', 'Julien morel', 'Monsieur', 'M. morel', 'Difficultés liées au suivi des stocks', 'Manque de coordination entre équipes de production', 'Suivi centralisé et automatisé des stocks critiques avec alertes préventives', 'Meilleure intégration des plannings des équipes dans l’erp', 'M. martin', 'Ajout module gestion des stocks avancé erp', 'Amélioration outils collaboratifs système', 'Options', 'Mise à disposition d’un portail d’analyse', 'Création d’un dashboard', 'Intégration d’un système d’alertes', 'Base operation', 'Segmentation des audiences', 'Applicatif de gestion des relations clients', 'Centraliser organiser exploiter informations', 'Acces', '[[base operation]]', 'M. dupont', 'Importance complétude des champs', 'Actions suivantes', 'Mise en place de contrôles automatiques', 'Besoin d’accéder à des données plus complètes', 'Performances des fournisseurs', 'Historique des commandes', 'Données complètes', 'Identifier goulets d’étranglement', 'Dupont', 'Problèmes liés à la situation actuelle', 'Amélioration des relations fournisseurs', 'Réduction des dépenses', 'Données de production', 'Certaines périodes', 'Assurer complétude des données', 'Précision accrue des kpi', 'Gain de temps pour équipes d’analyse', 'Identification', 'Organisation', 'Équipes opérationnelles', 'Complétude des informations', 'Taux d’ouverture des e-mails', 'Pertinence des messages', 'Emails', 'Thomas dupont', 'Besoins d’accès à la base opération', 'Gestion des achats', 'Accès direct']\n",
      "Edges: [('Document', 'Aspects techniques du datawarehouse'), ('Document', 'Spécifications des flux de données'), ('Document', 'Caractéristiques techniques'), ('Description', 'Datawarehouse'), ('Description', 'Erp'), ('Datawarehouse', 'Réservoir central'), ('Datawarehouse', 'Données consolidées'), ('Datawarehouse', 'Élément crucial'), ('Datawarehouse', 'Fiabilité'), ('Datawarehouse', 'Directeur de la production'), ('Datawarehouse', 'Erp'), ('Datawarehouse', 'Entite'), ('Datawarehouse', 'Acces'), ('Datawarehouse', 'Identification'), ('Postgresql 14', 'Base de données'), ('Modèle en étoile', 'Structure'), ('Accès', 'Politiques strictes'), ('Accès', 'Administrateurs système'), ('Accès', 'Indirect'), ('Contrats', 'Erp'), ('Erp', 'Système central de gestion'), ('Erp', 'Données relatives à'), ('Erp', 'Visibilité en temps réel'), ('Erp', 'Données'), ('Erp', 'Entite'), ('Interfaces', 'Transfert des données'), ('Interfaces', 'Informations précises et à jour'), ('Interface', 'Etl'), ('Outil', 'Talend data integration'), ('Source', 'Erp (sap'), ('Destination', 'Tables de faits et dimensions du datawarehouse'), ('Planification', 'Ordonnanceur cron'), ('Alertes', \"Emails et logs en cas d'échec\"), ('Gestion', 'Données'), ('Données', 'Fragmentées'), ('Validation', 'Contrôles sur les types et les règles métier'), ('Reporting', 'Tableau de bord sur les échecs de flux'), ('Rétention', '7 ans'), ('Archivage', 'Compression et stockage sur un serveur sftp'), ('Contraintes', 'Risques'), ('Risques', 'Pertes de données'), ('Risques', 'Erreurs de transformation'), ('Temps de latence', 'Erp et datawarehouse'), ('Maintenance', 'Interfaces etl'), ('Entite', 'Personne physique'), ('Entite', 'Field'), ('Entite', 'Base personne'), ('Entite', 'Crm'), ('Entite', 'Membre ecosysteme 1'), ('Field', 'Base operation'), ('Base personne', 'Segmentation des audiences'), ('Crm', 'Applicatif de gestion des relations clients'), ('Crm', 'Centraliser organiser exploiter informations'), ('Crm', 'Emails'), ('Responsables de production', 'Besoins'), ('Responsables de production', 'Problématiques'), ('Julien morel', 'Monsieur'), ('M. morel', 'Difficultés liées au suivi des stocks'), ('M. morel', 'Manque de coordination entre équipes de production'), ('M. morel', 'Suivi centralisé et automatisé des stocks critiques avec alertes préventives'), ('M. morel', 'Meilleure intégration des plannings des équipes dans l’erp'), ('M. martin', 'Ajout module gestion des stocks avancé erp'), ('M. martin', 'Amélioration outils collaboratifs système'), ('M. martin', 'Options'), ('M. martin', 'Mise à disposition d’un portail d’analyse'), ('M. martin', 'Création d’un dashboard'), ('M. martin', 'Intégration d’un système d’alertes'), ('Acces', '[[base operation]]'), ('M. dupont', 'Importance complétude des champs'), ('M. dupont', 'Actions suivantes'), ('M. dupont', 'Mise en place de contrôles automatiques'), ('M. dupont', 'Besoin d’accéder à des données plus complètes'), ('M. dupont', 'Performances des fournisseurs'), ('M. dupont', 'Historique des commandes'), ('Performances des fournisseurs', 'Accès direct'), ('Données complètes', 'Identifier goulets d’étranglement'), ('Dupont', 'Problèmes liés à la situation actuelle'), ('Dupont', 'Amélioration des relations fournisseurs'), ('Dupont', 'Réduction des dépenses'), ('Données de production', 'Certaines périodes'), ('Assurer complétude des données', 'Précision accrue des kpi'), ('Assurer complétude des données', 'Gain de temps pour équipes d’analyse'), ('Organisation', 'Équipes opérationnelles'), ('Complétude des informations', 'Taux d’ouverture des e-mails'), ('Complétude des informations', 'Pertinence des messages'), ('Thomas dupont', 'Besoins d’accès à la base opération'), ('Thomas dupont', 'Gestion des achats')]\n"
     ]
    }
   ],
   "source": [
    "g = graph_index.get_networkx_graph()\n",
    "print(g)\n",
    "print(\"Nodes:\", g.nodes())\n",
    "print(\"Edges:\", g.edges())\n",
    "net = Network(notebook=True, cdn_resources=\"in_line\", directed=True)\n",
    "net.from_nx(g)\n",
    "\n",
    "with open(\"knowledge_graph.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(net.generate_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3d6f30",
   "metadata": {},
   "source": [
    "### Set retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "330e38ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "801156d5f46b4b2aa06e9b2f88d000c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 4a9725f2-a5cd-47ab-a5cf-c6ff2c957b8e: 5.2 Risques\n",
      "\n",
      "- Panne des interfaces ETL pouvant interrompre les flux de donné...\n",
      "> Querying with idx: 4a9725f2-a5cd-47ab-a5cf-c6ff2c957b8e: 5.2 Risques\n",
      "\n",
      "- Panne des interfaces ETL pouvant interrompre les flux de donné...\n",
      "> Querying with idx: 4a9725f2-a5cd-47ab-a5cf-c6ff2c957b8e: 5.2 Risques\n",
      "\n",
      "- Panne des interfaces ETL pouvant interrompre les flux de donné...\n",
      "> Querying with idx: 4a9725f2-a5cd-47ab-a5cf-c6ff2c957b8e: 5.2 Risques\n",
      "\n",
      "- Panne des interfaces ETL pouvant interrompre les flux de donné...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 08b06ef3-6916-491a-a44d-31cf8e4fa62c: ---\n",
      "entite: applicatif\n",
      "feeds: \"[[Datawarehouse]]\"\n",
      "---\n",
      "Ce document détaille le...\n",
      "> Querying with idx: 08b06ef3-6916-491a-a44d-31cf8e4fa62c: ---\n",
      "entite: applicatif\n",
      "feeds: \"[[Datawarehouse]]\"\n",
      "---\n",
      "Ce document détaille le...\n",
      "> Querying with idx: 08b06ef3-6916-491a-a44d-31cf8e4fa62c: ---\n",
      "entite: applicatif\n",
      "feeds: \"[[Datawarehouse]]\"\n",
      "---\n",
      "Ce document détaille le...\n",
      "> Querying with idx: 08b06ef3-6916-491a-a44d-31cf8e4fa62c: ---\n",
      "entite: applicatif\n",
      "feeds: \"[[Datawarehouse]]\"\n",
      "---\n",
      "Ce document détaille le...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 0ef83e4e-956b-4a9a-a07c-c98c95636658: ---\n",
      "entite: base\n",
      "---\n",
      "Ce document a pour objectif de décrire les aspects techn...\n",
      "> Querying with idx: 0ef83e4e-956b-4a9a-a07c-c98c95636658: ---\n",
      "entite: base\n",
      "---\n",
      "Ce document a pour objectif de décrire les aspects techn...\n",
      "> Querying with idx: 0ef83e4e-956b-4a9a-a07c-c98c95636658: ---\n",
      "entite: base\n",
      "---\n",
      "Ce document a pour objectif de décrire les aspects techn...\n",
      "> Querying with idx: 0ef83e4e-956b-4a9a-a07c-c98c95636658: ---\n",
      "entite: base\n",
      "---\n",
      "Ce document a pour objectif de décrire les aspects techn...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 6ffd556c-718a-46fb-a6f6-6e30001b1a62: ---\n",
      "entite: base\n",
      "parent: \"[[ERP]]\"\n",
      "---\n",
      "La base de données \"Opérations\" est un...\n",
      "> Querying with idx: 6ffd556c-718a-46fb-a6f6-6e30001b1a62: ---\n",
      "entite: base\n",
      "parent: \"[[ERP]]\"\n",
      "---\n",
      "La base de données \"Opérations\" est un...\n",
      "> Querying with idx: 6ffd556c-718a-46fb-a6f6-6e30001b1a62: ---\n",
      "entite: base\n",
      "parent: \"[[ERP]]\"\n",
      "---\n",
      "La base de données \"Opérations\" est un...\n",
      "> Querying with idx: 6ffd556c-718a-46fb-a6f6-6e30001b1a62: ---\n",
      "entite: base\n",
      "parent: \"[[ERP]]\"\n",
      "---\n",
      "La base de données \"Opérations\" est un...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: eb770add-bc93-41ea-b08c-3dad0d299bfb: Prochaines Étapes\n",
      "\n",
      "1. Identification des champs critiques et prioritaires dan...\n",
      "> Querying with idx: eb770add-bc93-41ea-b08c-3dad0d299bfb: Prochaines Étapes\n",
      "\n",
      "1. Identification des champs critiques et prioritaires dan...\n",
      "> Querying with idx: eb770add-bc93-41ea-b08c-3dad0d299bfb: Prochaines Étapes\n",
      "\n",
      "1. Identification des champs critiques et prioritaires dan...\n",
      "> Querying with idx: eb770add-bc93-41ea-b08c-3dad0d299bfb: Prochaines Étapes\n",
      "\n",
      "1. Identification des champs critiques et prioritaires dan...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: ced72763-e189-4b56-94ca-e3fe1ed56697: 5.1 Contraintes\n",
      "\n",
      "- Temps de latence entre l’ERP et le Datawarehouse\n",
      "- Complex...\n",
      "> Querying with idx: ced72763-e189-4b56-94ca-e3fe1ed56697: 5.1 Contraintes\n",
      "\n",
      "- Temps de latence entre l’ERP et le Datawarehouse\n",
      "- Complex...\n",
      "> Querying with idx: ced72763-e189-4b56-94ca-e3fe1ed56697: 5.1 Contraintes\n",
      "\n",
      "- Temps de latence entre l’ERP et le Datawarehouse\n",
      "- Complex...\n",
      "> Querying with idx: ced72763-e189-4b56-94ca-e3fe1ed56697: 5.1 Contraintes\n",
      "\n",
      "- Temps de latence entre l’ERP et le Datawarehouse\n",
      "- Complex...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 2d93f7b2-4f8f-4f21-88fc-573dc718e68f: 6. Conclusion\n",
      "\n",
      "L’ERP joue un rôle essentiel dans l’alimentation du Datawareho...\n",
      "> Querying with idx: 2d93f7b2-4f8f-4f21-88fc-573dc718e68f: 6. Conclusion\n",
      "\n",
      "L’ERP joue un rôle essentiel dans l’alimentation du Datawareho...\n",
      "> Querying with idx: 2d93f7b2-4f8f-4f21-88fc-573dc718e68f: 6. Conclusion\n",
      "\n",
      "L’ERP joue un rôle essentiel dans l’alimentation du Datawareho...\n",
      "> Querying with idx: 2d93f7b2-4f8f-4f21-88fc-573dc718e68f: 6. Conclusion\n",
      "\n",
      "L’ERP joue un rôle essentiel dans l’alimentation du Datawareho...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: b51fda10-72af-4ac6-bab9-edd7267fd758: Relations avec d'autres Tables\n",
      "\n",
      "- **Table `utilisateurs`** :\n",
      "    - Relation p...\n",
      "> Querying with idx: b51fda10-72af-4ac6-bab9-edd7267fd758: Relations avec d'autres Tables\n",
      "\n",
      "- **Table `utilisateurs`** :\n",
      "    - Relation p...\n",
      "> Querying with idx: b51fda10-72af-4ac6-bab9-edd7267fd758: Relations avec d'autres Tables\n",
      "\n",
      "- **Table `utilisateurs`** :\n",
      "    - Relation p...\n",
      "> Querying with idx: b51fda10-72af-4ac6-bab9-edd7267fd758: Relations avec d'autres Tables\n",
      "\n",
      "- **Table `utilisateurs`** :\n",
      "    - Relation p...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 0b6ed73f-12a4-4242-a2df-b61584f5b55a: 3. Contrats d'Interface avec l'ERP\n",
      "> Querying with idx: 0b6ed73f-12a4-4242-a2df-b61584f5b55a: 3. Contrats d'Interface avec l'ERP\n",
      "> Querying with idx: 0b6ed73f-12a4-4242-a2df-b61584f5b55a: 3. Contrats d'Interface avec l'ERP\n",
      "> Querying with idx: 0b6ed73f-12a4-4242-a2df-b61584f5b55a: 3. Contrats d'Interface avec l'ERP\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 93f4fbfa-1d6a-4ed2-8abb-98aba87976d2: Ajout d'une Opération\n",
      "\n",
      "```sql\n",
      "INSERT INTO operations (nom_op, description_op,...\n",
      "> Querying with idx: 93f4fbfa-1d6a-4ed2-8abb-98aba87976d2: Ajout d'une Opération\n",
      "\n",
      "```sql\n",
      "INSERT INTO operations (nom_op, description_op,...\n",
      "> Querying with idx: 93f4fbfa-1d6a-4ed2-8abb-98aba87976d2: Ajout d'une Opération\n",
      "\n",
      "```sql\n",
      "INSERT INTO operations (nom_op, description_op,...\n",
      "> Querying with idx: 93f4fbfa-1d6a-4ed2-8abb-98aba87976d2: Ajout d'une Opération\n",
      "\n",
      "```sql\n",
      "INSERT INTO operations (nom_op, description_op,...\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "graph_query_engine = graph_index.as_query_engine(\n",
    " include_text=True,\n",
    " response_mode=\"tree_summarize\",\n",
    " embedding_mode=\"hybrid\",\n",
    " similarity_top_k=8,\n",
    ")\n",
    "\n",
    "response = graph_query_engine.query(\n",
    "    \"Je dois lancer un nouveau projet data avec mes données opérationnelles, qui puis-je impliquer, et pour faire quoi ?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "53d2c82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour lancer un nouveau projet data avec vos données opérationnelles, vous pouvez impliquer plusieurs parties prenantes :\n",
       "\n",
       "1. **Équipes opérationnelles** : Elles peuvent être formées pour comprendre les nouvelles règles et processus liés à l'utilisation des données dans le projet. Une formation est prévue pour ces équipes, ce qui peut être une bonne occasion de les impliquer.\n",
       "\n",
       "2. **Responsables des opérations** : Ils peuvent être impliqués pour superviser l'intégration des données opérationnelles dans le projet. Par exemple, un responsable comme Jean Dupont pourrait être désigné pour suivre le projet.\n",
       "\n",
       "3. **Équipe technique de l'ERP et du Datawarehouse** : Ces équipes peuvent être cruciales pour gérer les flux de données entre l'ERP et le Datawarehouse, en s'assurant que les données sont correctement synchronisées et intégrées.\n",
       "\n",
       "4. **Spécialistes en ETL** : Ils peuvent être impliqués pour mettre en place des règles de validation automatique et gérer les transformations complexes des données.\n",
       "\n",
       "5. **Gestionnaires de projets** : Ils peuvent coordonner les différentes parties prenantes et s'assurer que le projet respecte les délais et les objectifs fixés.\n",
       "\n",
       "En impliquant ces parties, vous pouvez vous assurer que le projet est bien structuré et que les données opérationnelles sont utilisées efficacement.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96e323b",
   "metadata": {},
   "source": [
    "### Test retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c0dd0ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df191367c2f4cc69527d439429b95c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 4a9725f2-a5cd-47ab-a5cf-c6ff2c957b8e: 5.2 Risques\n",
      "\n",
      "- Panne des interfaces ETL pouvant interrompre les flux de donné...\n",
      "> Querying with idx: 4a9725f2-a5cd-47ab-a5cf-c6ff2c957b8e: 5.2 Risques\n",
      "\n",
      "- Panne des interfaces ETL pouvant interrompre les flux de donné...\n",
      "> Querying with idx: 4a9725f2-a5cd-47ab-a5cf-c6ff2c957b8e: 5.2 Risques\n",
      "\n",
      "- Panne des interfaces ETL pouvant interrompre les flux de donné...\n",
      "> Querying with idx: 4a9725f2-a5cd-47ab-a5cf-c6ff2c957b8e: 5.2 Risques\n",
      "\n",
      "- Panne des interfaces ETL pouvant interrompre les flux de donné...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 08b06ef3-6916-491a-a44d-31cf8e4fa62c: ---\n",
      "entite: applicatif\n",
      "feeds: \"[[Datawarehouse]]\"\n",
      "---\n",
      "Ce document détaille le...\n",
      "> Querying with idx: 08b06ef3-6916-491a-a44d-31cf8e4fa62c: ---\n",
      "entite: applicatif\n",
      "feeds: \"[[Datawarehouse]]\"\n",
      "---\n",
      "Ce document détaille le...\n",
      "> Querying with idx: 08b06ef3-6916-491a-a44d-31cf8e4fa62c: ---\n",
      "entite: applicatif\n",
      "feeds: \"[[Datawarehouse]]\"\n",
      "---\n",
      "Ce document détaille le...\n",
      "> Querying with idx: 08b06ef3-6916-491a-a44d-31cf8e4fa62c: ---\n",
      "entite: applicatif\n",
      "feeds: \"[[Datawarehouse]]\"\n",
      "---\n",
      "Ce document détaille le...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 0ef83e4e-956b-4a9a-a07c-c98c95636658: ---\n",
      "entite: base\n",
      "---\n",
      "Ce document a pour objectif de décrire les aspects techn...\n",
      "> Querying with idx: 0ef83e4e-956b-4a9a-a07c-c98c95636658: ---\n",
      "entite: base\n",
      "---\n",
      "Ce document a pour objectif de décrire les aspects techn...\n",
      "> Querying with idx: 0ef83e4e-956b-4a9a-a07c-c98c95636658: ---\n",
      "entite: base\n",
      "---\n",
      "Ce document a pour objectif de décrire les aspects techn...\n",
      "> Querying with idx: 0ef83e4e-956b-4a9a-a07c-c98c95636658: ---\n",
      "entite: base\n",
      "---\n",
      "Ce document a pour objectif de décrire les aspects techn...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 6ffd556c-718a-46fb-a6f6-6e30001b1a62: ---\n",
      "entite: base\n",
      "parent: \"[[ERP]]\"\n",
      "---\n",
      "La base de données \"Opérations\" est un...\n",
      "> Querying with idx: 6ffd556c-718a-46fb-a6f6-6e30001b1a62: ---\n",
      "entite: base\n",
      "parent: \"[[ERP]]\"\n",
      "---\n",
      "La base de données \"Opérations\" est un...\n",
      "> Querying with idx: 6ffd556c-718a-46fb-a6f6-6e30001b1a62: ---\n",
      "entite: base\n",
      "parent: \"[[ERP]]\"\n",
      "---\n",
      "La base de données \"Opérations\" est un...\n",
      "> Querying with idx: 6ffd556c-718a-46fb-a6f6-6e30001b1a62: ---\n",
      "entite: base\n",
      "parent: \"[[ERP]]\"\n",
      "---\n",
      "La base de données \"Opérations\" est un...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: eb770add-bc93-41ea-b08c-3dad0d299bfb: Prochaines Étapes\n",
      "\n",
      "1. Identification des champs critiques et prioritaires dan...\n",
      "> Querying with idx: eb770add-bc93-41ea-b08c-3dad0d299bfb: Prochaines Étapes\n",
      "\n",
      "1. Identification des champs critiques et prioritaires dan...\n",
      "> Querying with idx: eb770add-bc93-41ea-b08c-3dad0d299bfb: Prochaines Étapes\n",
      "\n",
      "1. Identification des champs critiques et prioritaires dan...\n",
      "> Querying with idx: eb770add-bc93-41ea-b08c-3dad0d299bfb: Prochaines Étapes\n",
      "\n",
      "1. Identification des champs critiques et prioritaires dan...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: ced72763-e189-4b56-94ca-e3fe1ed56697: 5.1 Contraintes\n",
      "\n",
      "- Temps de latence entre l’ERP et le Datawarehouse\n",
      "- Complex...\n",
      "> Querying with idx: ced72763-e189-4b56-94ca-e3fe1ed56697: 5.1 Contraintes\n",
      "\n",
      "- Temps de latence entre l’ERP et le Datawarehouse\n",
      "- Complex...\n",
      "> Querying with idx: ced72763-e189-4b56-94ca-e3fe1ed56697: 5.1 Contraintes\n",
      "\n",
      "- Temps de latence entre l’ERP et le Datawarehouse\n",
      "- Complex...\n",
      "> Querying with idx: ced72763-e189-4b56-94ca-e3fe1ed56697: 5.1 Contraintes\n",
      "\n",
      "- Temps de latence entre l’ERP et le Datawarehouse\n",
      "- Complex...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 2d93f7b2-4f8f-4f21-88fc-573dc718e68f: 6. Conclusion\n",
      "\n",
      "L’ERP joue un rôle essentiel dans l’alimentation du Datawareho...\n",
      "> Querying with idx: 2d93f7b2-4f8f-4f21-88fc-573dc718e68f: 6. Conclusion\n",
      "\n",
      "L’ERP joue un rôle essentiel dans l’alimentation du Datawareho...\n",
      "> Querying with idx: 2d93f7b2-4f8f-4f21-88fc-573dc718e68f: 6. Conclusion\n",
      "\n",
      "L’ERP joue un rôle essentiel dans l’alimentation du Datawareho...\n",
      "> Querying with idx: 2d93f7b2-4f8f-4f21-88fc-573dc718e68f: 6. Conclusion\n",
      "\n",
      "L’ERP joue un rôle essentiel dans l’alimentation du Datawareho...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: b51fda10-72af-4ac6-bab9-edd7267fd758: Relations avec d'autres Tables\n",
      "\n",
      "- **Table `utilisateurs`** :\n",
      "    - Relation p...\n",
      "> Querying with idx: b51fda10-72af-4ac6-bab9-edd7267fd758: Relations avec d'autres Tables\n",
      "\n",
      "- **Table `utilisateurs`** :\n",
      "    - Relation p...\n",
      "> Querying with idx: b51fda10-72af-4ac6-bab9-edd7267fd758: Relations avec d'autres Tables\n",
      "\n",
      "- **Table `utilisateurs`** :\n",
      "    - Relation p...\n",
      "> Querying with idx: b51fda10-72af-4ac6-bab9-edd7267fd758: Relations avec d'autres Tables\n",
      "\n",
      "- **Table `utilisateurs`** :\n",
      "    - Relation p...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 0b6ed73f-12a4-4242-a2df-b61584f5b55a: 3. Contrats d'Interface avec l'ERP\n",
      "> Querying with idx: 0b6ed73f-12a4-4242-a2df-b61584f5b55a: 3. Contrats d'Interface avec l'ERP\n",
      "> Querying with idx: 0b6ed73f-12a4-4242-a2df-b61584f5b55a: 3. Contrats d'Interface avec l'ERP\n",
      "> Querying with idx: 0b6ed73f-12a4-4242-a2df-b61584f5b55a: 3. Contrats d'Interface avec l'ERP\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 93f4fbfa-1d6a-4ed2-8abb-98aba87976d2: Ajout d'une Opération\n",
      "\n",
      "```sql\n",
      "INSERT INTO operations (nom_op, description_op,...\n",
      "> Querying with idx: 93f4fbfa-1d6a-4ed2-8abb-98aba87976d2: Ajout d'une Opération\n",
      "\n",
      "```sql\n",
      "INSERT INTO operations (nom_op, description_op,...\n",
      "> Querying with idx: 93f4fbfa-1d6a-4ed2-8abb-98aba87976d2: Ajout d'une Opération\n",
      "\n",
      "```sql\n",
      "INSERT INTO operations (nom_op, description_op,...\n",
      "> Querying with idx: 93f4fbfa-1d6a-4ed2-8abb-98aba87976d2: Ajout d'une Opération\n",
      "\n",
      "```sql\n",
      "INSERT INTO operations (nom_op, description_op,...\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "graph_rag_retriever = graph_index.as_retriever(\n",
    "    retriever_mode=\"hybrid\",  # or \"embedding\" or \"hybrid\"\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "response = graph_query_engine.query(\n",
    "    \"Je dois lancer un nouveau projet data avec mes données opérationnelles, qui puis-je impliquer, et pour faire quoi ?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d1031a44-f06e-400f-beaa-2065beeee9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour lancer un nouveau projet data avec vos données opérationnelles, vous pouvez impliquer plusieurs parties prenantes :\n",
       "\n",
       "1. **Équipes opérationnelles** : Elles peuvent être formées pour comprendre les nouvelles règles et processus liés au projet. Une formation est prévue pour ces équipes, ce qui les rend essentielles pour le succès du projet.\n",
       "\n",
       "2. **Responsables des opérations** : Ils peuvent être impliqués pour superviser et gérer les aspects opérationnels du projet. Par exemple, un responsable comme Jean Dupont pourrait être désigné pour suivre le projet.\n",
       "\n",
       "3. **Équipe technique de l'ERP et du Datawarehouse** : Ces équipes sont cruciales pour assurer la synchronisation et l'intégration des données entre l'ERP et le Datawarehouse. Elles peuvent travailler sur les flux de données, les transformations nécessaires, et la mise en place de règles de validation automatique dans les processus ETL.\n",
       "\n",
       "4. **Gestionnaires de projets** : Ils peuvent coordonner les différentes parties prenantes, gérer les délais, et s'assurer que les objectifs du projet sont atteints.\n",
       "\n",
       "Ensemble, ces parties prenantes peuvent collaborer pour garantir que le projet est bien structuré, que les données sont correctement intégrées et que les objectifs stratégiques de l'entreprise sont atteints.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1e7541",
   "metadata": {},
   "source": [
    "## Load onto index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bb203e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.loading:Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n"
     ]
    }
   ],
   "source": [
    "onto_storage_context = StorageContext.from_defaults(persist_dir=\"onto_graph\")\n",
    "# Load the PropertyGraphIndex from the storage context\n",
    "\n",
    "onto_index = load_index_from_storage(onto_storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a182d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "onto_index.property_graph_store.save_networkx_graph(\n",
    "    name=\"OntoGraph.html\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e4dcae",
   "metadata": {},
   "source": [
    "### Set retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bee17732",
   "metadata": {},
   "outputs": [],
   "source": [
    "onto_query_engine = onto_index.as_query_engine(\n",
    " include_text=True,\n",
    " similarity_top_k=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95920ba",
   "metadata": {},
   "source": [
    "### Test retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4c400086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "015678d2f9e9413db5544bffa041798b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "onto_rag_retriever = onto_index.as_retriever(\n",
    "    retriever_mode=\"hybrid\",  # or \"embedding\" or \"hybrid\"\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "response = onto_query_engine.query(\n",
    "    \"Je dois lancer un nouveau projet data avec mes données opérationnelles, qui puis-je impliquer, et pour faire quoi ?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "123366e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour lancer un nouveau projet data avec vos données opérationnelles, vous pouvez impliquer plusieurs parties prenantes et définir des rôles spécifiques :\n",
       "\n",
       "1. **Équipes Opérationnelles et IT** : Collaborez étroitement avec ces équipes pour définir les priorités des données critiques et assurer une intégration fluide des données dans le Datawarehouse.\n",
       "\n",
       "2. **Responsable de Projet** : Une personne comme Jean Dupont, qui a déjà une expérience dans la gestion des opérations, pourrait être responsable de superviser le projet et de coordonner les différentes équipes.\n",
       "\n",
       "3. **Équipe de Formation** : Organisez une session de formation pour les équipes terrain afin de les sensibiliser à l'importance de la saisie complète des données dans l'ERP, ce qui est crucial pour la qualité des données opérationnelles.\n",
       "\n",
       "4. **Spécialistes en ETL** : Mettez en place des contrôles automatiques pour détecter et signaler les champs manquants lors des processus ETL, garantissant ainsi la qualité et la complétude des données transférées.\n",
       "\n",
       "5. **Analystes de Données** : Ils peuvent travailler sur l'audit des données disponibles et identifier les champs pertinents pour le projet, en s'assurant que les données critiques sont bien intégrées et exploitables.\n",
       "\n",
       "En impliquant ces parties prenantes, vous pouvez assurer une gestion efficace et une utilisation optimale de vos données opérationnelles pour le projet.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474b65be-955e-44db-942e-27e235384f19",
   "metadata": {},
   "source": [
    "# Visualize knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "55ef03a2-2e7e-443d-865f-b6d991d16416",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = graph_index.get_networkx_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b9d58e14-0017-494f-98ec-ad8b30bf8c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in the knowledge graph: 87\n"
     ]
    }
   ],
   "source": [
    "# Count the number of nodes\n",
    "num_nodes = len(nx_graph.edges())\n",
    "\n",
    "print(f\"Number of nodes in the knowledge graph: {num_nodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a113918c-f195-4c8c-b0f3-c85d7a6c5d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 116 nodes and 87 edges\n",
      "Nodes: ['Document', 'Aspects techniques du datawarehouse', 'Spécifications des flux de données', 'Caractéristiques techniques', 'Description', 'Datawarehouse', 'Réservoir central', 'Données consolidées', 'Élément crucial', 'Fiabilité', 'Postgresql 14', 'Base de données', 'Modèle en étoile', 'Structure', 'Directeur de la production', 'Accès', 'Politiques strictes', 'Administrateurs système', 'Indirect', 'Contrats', 'Erp', 'Système central de gestion', 'Données relatives à', 'Visibilité en temps réel', 'Interfaces', 'Transfert des données', 'Informations précises et à jour', 'Interface', 'Etl', 'Outil', 'Talend data integration', 'Source', 'Erp (sap', 'Destination', 'Tables de faits et dimensions du datawarehouse', 'Planification', 'Ordonnanceur cron', 'Alertes', \"Emails et logs en cas d'échec\", 'Gestion', 'Données', 'Fragmentées', 'Validation', 'Contrôles sur les types et les règles métier', 'Reporting', 'Tableau de bord sur les échecs de flux', 'Rétention', '7 ans', 'Archivage', 'Compression et stockage sur un serveur sftp', 'Contraintes', 'Risques', 'Pertes de données', 'Erreurs de transformation', 'Temps de latence', 'Erp et datawarehouse', 'Maintenance', 'Interfaces etl', 'Entite', 'Personne physique', 'Field', 'Base personne', 'Crm', 'Membre ecosysteme 1', 'Responsables de production', 'Besoins', 'Problématiques', 'Julien morel', 'Monsieur', 'M. morel', 'Difficultés liées au suivi des stocks', 'Manque de coordination entre équipes de production', 'Suivi centralisé et automatisé des stocks critiques avec alertes préventives', 'Meilleure intégration des plannings des équipes dans l’erp', 'M. martin', 'Ajout module gestion des stocks avancé erp', 'Amélioration outils collaboratifs système', 'Options', 'Mise à disposition d’un portail d’analyse', 'Création d’un dashboard', 'Intégration d’un système d’alertes', 'Base operation', 'Segmentation des audiences', 'Applicatif de gestion des relations clients', 'Centraliser organiser exploiter informations', 'Acces', '[[base operation]]', 'M. dupont', 'Importance complétude des champs', 'Actions suivantes', 'Mise en place de contrôles automatiques', 'Besoin d’accéder à des données plus complètes', 'Performances des fournisseurs', 'Historique des commandes', 'Données complètes', 'Identifier goulets d’étranglement', 'Dupont', 'Problèmes liés à la situation actuelle', 'Amélioration des relations fournisseurs', 'Réduction des dépenses', 'Données de production', 'Certaines périodes', 'Assurer complétude des données', 'Précision accrue des kpi', 'Gain de temps pour équipes d’analyse', 'Identification', 'Organisation', 'Équipes opérationnelles', 'Complétude des informations', 'Taux d’ouverture des e-mails', 'Pertinence des messages', 'Emails', 'Thomas dupont', 'Besoins d’accès à la base opération', 'Gestion des achats', 'Accès direct']\n",
      "Edges: [('Document', 'Aspects techniques du datawarehouse'), ('Document', 'Spécifications des flux de données'), ('Document', 'Caractéristiques techniques'), ('Description', 'Datawarehouse'), ('Description', 'Erp'), ('Datawarehouse', 'Réservoir central'), ('Datawarehouse', 'Données consolidées'), ('Datawarehouse', 'Élément crucial'), ('Datawarehouse', 'Fiabilité'), ('Datawarehouse', 'Directeur de la production'), ('Datawarehouse', 'Erp'), ('Datawarehouse', 'Entite'), ('Datawarehouse', 'Acces'), ('Datawarehouse', 'Identification'), ('Postgresql 14', 'Base de données'), ('Modèle en étoile', 'Structure'), ('Accès', 'Politiques strictes'), ('Accès', 'Administrateurs système'), ('Accès', 'Indirect'), ('Contrats', 'Erp'), ('Erp', 'Système central de gestion'), ('Erp', 'Données relatives à'), ('Erp', 'Visibilité en temps réel'), ('Erp', 'Données'), ('Erp', 'Entite'), ('Interfaces', 'Transfert des données'), ('Interfaces', 'Informations précises et à jour'), ('Interface', 'Etl'), ('Outil', 'Talend data integration'), ('Source', 'Erp (sap'), ('Destination', 'Tables de faits et dimensions du datawarehouse'), ('Planification', 'Ordonnanceur cron'), ('Alertes', \"Emails et logs en cas d'échec\"), ('Gestion', 'Données'), ('Données', 'Fragmentées'), ('Validation', 'Contrôles sur les types et les règles métier'), ('Reporting', 'Tableau de bord sur les échecs de flux'), ('Rétention', '7 ans'), ('Archivage', 'Compression et stockage sur un serveur sftp'), ('Contraintes', 'Risques'), ('Risques', 'Pertes de données'), ('Risques', 'Erreurs de transformation'), ('Temps de latence', 'Erp et datawarehouse'), ('Maintenance', 'Interfaces etl'), ('Entite', 'Personne physique'), ('Entite', 'Field'), ('Entite', 'Base personne'), ('Entite', 'Crm'), ('Entite', 'Membre ecosysteme 1'), ('Field', 'Base operation'), ('Base personne', 'Segmentation des audiences'), ('Crm', 'Applicatif de gestion des relations clients'), ('Crm', 'Centraliser organiser exploiter informations'), ('Crm', 'Emails'), ('Responsables de production', 'Besoins'), ('Responsables de production', 'Problématiques'), ('Julien morel', 'Monsieur'), ('M. morel', 'Difficultés liées au suivi des stocks'), ('M. morel', 'Manque de coordination entre équipes de production'), ('M. morel', 'Suivi centralisé et automatisé des stocks critiques avec alertes préventives'), ('M. morel', 'Meilleure intégration des plannings des équipes dans l’erp'), ('M. martin', 'Ajout module gestion des stocks avancé erp'), ('M. martin', 'Amélioration outils collaboratifs système'), ('M. martin', 'Options'), ('M. martin', 'Mise à disposition d’un portail d’analyse'), ('M. martin', 'Création d’un dashboard'), ('M. martin', 'Intégration d’un système d’alertes'), ('Acces', '[[base operation]]'), ('M. dupont', 'Importance complétude des champs'), ('M. dupont', 'Actions suivantes'), ('M. dupont', 'Mise en place de contrôles automatiques'), ('M. dupont', 'Besoin d’accéder à des données plus complètes'), ('M. dupont', 'Performances des fournisseurs'), ('M. dupont', 'Historique des commandes'), ('Performances des fournisseurs', 'Accès direct'), ('Données complètes', 'Identifier goulets d’étranglement'), ('Dupont', 'Problèmes liés à la situation actuelle'), ('Dupont', 'Amélioration des relations fournisseurs'), ('Dupont', 'Réduction des dépenses'), ('Données de production', 'Certaines périodes'), ('Assurer complétude des données', 'Précision accrue des kpi'), ('Assurer complétude des données', 'Gain de temps pour équipes d’analyse'), ('Organisation', 'Équipes opérationnelles'), ('Complétude des informations', 'Taux d’ouverture des e-mails'), ('Complétude des informations', 'Pertinence des messages'), ('Thomas dupont', 'Besoins d’accès à la base opération'), ('Thomas dupont', 'Gestion des achats')]\n"
     ]
    }
   ],
   "source": [
    "g = graph_index.get_networkx_graph()\n",
    "print(g)\n",
    "print(\"Nodes:\", g.nodes())\n",
    "print(\"Edges:\", g.edges())\n",
    "net = Network(notebook=True, cdn_resources=\"in_line\", directed=True)\n",
    "net.from_nx(g)\n",
    "\n",
    "with open(\"knowledge_graph.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(net.generate_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab94fc0-2080-4869-94a0-b013dc0fbd9d",
   "metadata": {},
   "source": [
    "# (Simple) Query the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6c93bdbb-aaa4-4658-aecf-1cd7b5038ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffdd103210d84868a8396d1b63e5ad9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "query = \"Je dois lancer un nouveau projet data avec mes données opérationnelles, qui puis-je impliquer, et pour faire quoi ?\"\n",
    "query_engine = simple_index.as_query_engine(\n",
    " include_text=True,\n",
    " response_mode=\"tree_summarize\",\n",
    " embedding_mode=\"hybrid\",\n",
    " similarity_top_k=8,\n",
    ")\n",
    "\n",
    "response = query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e2a871b4-70c8-45ed-a8b9-b2aaa8d15a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour lancer un nouveau projet data avec vos données opérationnelles, vous pouvez impliquer plusieurs personnes et équipes clés :\n",
       "\n",
       "1. **Mme Laurent** : Elle a exprimé le besoin d'accéder à des données plus complètes et en temps réel. Vous pouvez l'impliquer pour définir les besoins en données et les indicateurs clés de performance (KPIs) à suivre.\n",
       "\n",
       "2. **M. Dupont** : En tant que directeur de production, il a souligné l'importance de la complétude des champs dans le Datawarehouse. Il peut être impliqué pour s'assurer que les données sont complètes et fiables, et pour superviser la mise en place de contrôles automatiques pour détecter les champs manquants.\n",
       "\n",
       "3. **Équipes opérationnelles** : Elles devraient être formées pour comprendre l'importance de la saisie complète des données et pour collaborer avec l'équipe IT afin de définir les priorités des données critiques.\n",
       "\n",
       "4. **Équipe IT** : Pour mettre en place les règles de validation automatique dans les processus ETL et pour assurer la sécurité et la sauvegarde des données.\n",
       "\n",
       "5. **Responsable de la base de données \"Opérations\"** : Pour garantir une documentation claire et détaillée, facilitant l'utilisation et la maintenance de la base de données.\n",
       "\n",
       "Ces collaborations permettront de structurer efficacement votre projet data et d'optimiser l'utilisation des données opérationnelles.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b099031c-b137-468f-b20c-9c6fab1c4eb1",
   "metadata": {},
   "source": [
    "# (Simple) Query the knowledge graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8948dd2b-acd4-4621-a2d1-b45034a21007",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7df5b5e202054c0a958480ffa7ae4042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 4a9725f2-a5cd-47ab-a5cf-c6ff2c957b8e: 5.2 Risques\n",
      "\n",
      "- Panne des interfaces ETL pouvant interrompre les flux de donné...\n",
      "> Querying with idx: 4a9725f2-a5cd-47ab-a5cf-c6ff2c957b8e: 5.2 Risques\n",
      "\n",
      "- Panne des interfaces ETL pouvant interrompre les flux de donné...\n",
      "> Querying with idx: 4a9725f2-a5cd-47ab-a5cf-c6ff2c957b8e: 5.2 Risques\n",
      "\n",
      "- Panne des interfaces ETL pouvant interrompre les flux de donné...\n",
      "> Querying with idx: 4a9725f2-a5cd-47ab-a5cf-c6ff2c957b8e: 5.2 Risques\n",
      "\n",
      "- Panne des interfaces ETL pouvant interrompre les flux de donné...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 08b06ef3-6916-491a-a44d-31cf8e4fa62c: ---\n",
      "entite: applicatif\n",
      "feeds: \"[[Datawarehouse]]\"\n",
      "---\n",
      "Ce document détaille le...\n",
      "> Querying with idx: 08b06ef3-6916-491a-a44d-31cf8e4fa62c: ---\n",
      "entite: applicatif\n",
      "feeds: \"[[Datawarehouse]]\"\n",
      "---\n",
      "Ce document détaille le...\n",
      "> Querying with idx: 08b06ef3-6916-491a-a44d-31cf8e4fa62c: ---\n",
      "entite: applicatif\n",
      "feeds: \"[[Datawarehouse]]\"\n",
      "---\n",
      "Ce document détaille le...\n",
      "> Querying with idx: 08b06ef3-6916-491a-a44d-31cf8e4fa62c: ---\n",
      "entite: applicatif\n",
      "feeds: \"[[Datawarehouse]]\"\n",
      "---\n",
      "Ce document détaille le...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 0ef83e4e-956b-4a9a-a07c-c98c95636658: ---\n",
      "entite: base\n",
      "---\n",
      "Ce document a pour objectif de décrire les aspects techn...\n",
      "> Querying with idx: 0ef83e4e-956b-4a9a-a07c-c98c95636658: ---\n",
      "entite: base\n",
      "---\n",
      "Ce document a pour objectif de décrire les aspects techn...\n",
      "> Querying with idx: 0ef83e4e-956b-4a9a-a07c-c98c95636658: ---\n",
      "entite: base\n",
      "---\n",
      "Ce document a pour objectif de décrire les aspects techn...\n",
      "> Querying with idx: 0ef83e4e-956b-4a9a-a07c-c98c95636658: ---\n",
      "entite: base\n",
      "---\n",
      "Ce document a pour objectif de décrire les aspects techn...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 6ffd556c-718a-46fb-a6f6-6e30001b1a62: ---\n",
      "entite: base\n",
      "parent: \"[[ERP]]\"\n",
      "---\n",
      "La base de données \"Opérations\" est un...\n",
      "> Querying with idx: 6ffd556c-718a-46fb-a6f6-6e30001b1a62: ---\n",
      "entite: base\n",
      "parent: \"[[ERP]]\"\n",
      "---\n",
      "La base de données \"Opérations\" est un...\n",
      "> Querying with idx: 6ffd556c-718a-46fb-a6f6-6e30001b1a62: ---\n",
      "entite: base\n",
      "parent: \"[[ERP]]\"\n",
      "---\n",
      "La base de données \"Opérations\" est un...\n",
      "> Querying with idx: 6ffd556c-718a-46fb-a6f6-6e30001b1a62: ---\n",
      "entite: base\n",
      "parent: \"[[ERP]]\"\n",
      "---\n",
      "La base de données \"Opérations\" est un...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: eb770add-bc93-41ea-b08c-3dad0d299bfb: Prochaines Étapes\n",
      "\n",
      "1. Identification des champs critiques et prioritaires dan...\n",
      "> Querying with idx: eb770add-bc93-41ea-b08c-3dad0d299bfb: Prochaines Étapes\n",
      "\n",
      "1. Identification des champs critiques et prioritaires dan...\n",
      "> Querying with idx: eb770add-bc93-41ea-b08c-3dad0d299bfb: Prochaines Étapes\n",
      "\n",
      "1. Identification des champs critiques et prioritaires dan...\n",
      "> Querying with idx: eb770add-bc93-41ea-b08c-3dad0d299bfb: Prochaines Étapes\n",
      "\n",
      "1. Identification des champs critiques et prioritaires dan...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: ced72763-e189-4b56-94ca-e3fe1ed56697: 5.1 Contraintes\n",
      "\n",
      "- Temps de latence entre l’ERP et le Datawarehouse\n",
      "- Complex...\n",
      "> Querying with idx: ced72763-e189-4b56-94ca-e3fe1ed56697: 5.1 Contraintes\n",
      "\n",
      "- Temps de latence entre l’ERP et le Datawarehouse\n",
      "- Complex...\n",
      "> Querying with idx: ced72763-e189-4b56-94ca-e3fe1ed56697: 5.1 Contraintes\n",
      "\n",
      "- Temps de latence entre l’ERP et le Datawarehouse\n",
      "- Complex...\n",
      "> Querying with idx: ced72763-e189-4b56-94ca-e3fe1ed56697: 5.1 Contraintes\n",
      "\n",
      "- Temps de latence entre l’ERP et le Datawarehouse\n",
      "- Complex...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 2d93f7b2-4f8f-4f21-88fc-573dc718e68f: 6. Conclusion\n",
      "\n",
      "L’ERP joue un rôle essentiel dans l’alimentation du Datawareho...\n",
      "> Querying with idx: 2d93f7b2-4f8f-4f21-88fc-573dc718e68f: 6. Conclusion\n",
      "\n",
      "L’ERP joue un rôle essentiel dans l’alimentation du Datawareho...\n",
      "> Querying with idx: 2d93f7b2-4f8f-4f21-88fc-573dc718e68f: 6. Conclusion\n",
      "\n",
      "L’ERP joue un rôle essentiel dans l’alimentation du Datawareho...\n",
      "> Querying with idx: 2d93f7b2-4f8f-4f21-88fc-573dc718e68f: 6. Conclusion\n",
      "\n",
      "L’ERP joue un rôle essentiel dans l’alimentation du Datawareho...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: b51fda10-72af-4ac6-bab9-edd7267fd758: Relations avec d'autres Tables\n",
      "\n",
      "- **Table `utilisateurs`** :\n",
      "    - Relation p...\n",
      "> Querying with idx: b51fda10-72af-4ac6-bab9-edd7267fd758: Relations avec d'autres Tables\n",
      "\n",
      "- **Table `utilisateurs`** :\n",
      "    - Relation p...\n",
      "> Querying with idx: b51fda10-72af-4ac6-bab9-edd7267fd758: Relations avec d'autres Tables\n",
      "\n",
      "- **Table `utilisateurs`** :\n",
      "    - Relation p...\n",
      "> Querying with idx: b51fda10-72af-4ac6-bab9-edd7267fd758: Relations avec d'autres Tables\n",
      "\n",
      "- **Table `utilisateurs`** :\n",
      "    - Relation p...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 0b6ed73f-12a4-4242-a2df-b61584f5b55a: 3. Contrats d'Interface avec l'ERP\n",
      "> Querying with idx: 0b6ed73f-12a4-4242-a2df-b61584f5b55a: 3. Contrats d'Interface avec l'ERP\n",
      "> Querying with idx: 0b6ed73f-12a4-4242-a2df-b61584f5b55a: 3. Contrats d'Interface avec l'ERP\n",
      "> Querying with idx: 0b6ed73f-12a4-4242-a2df-b61584f5b55a: 3. Contrats d'Interface avec l'ERP\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 93f4fbfa-1d6a-4ed2-8abb-98aba87976d2: Ajout d'une Opération\n",
      "\n",
      "```sql\n",
      "INSERT INTO operations (nom_op, description_op,...\n",
      "> Querying with idx: 93f4fbfa-1d6a-4ed2-8abb-98aba87976d2: Ajout d'une Opération\n",
      "\n",
      "```sql\n",
      "INSERT INTO operations (nom_op, description_op,...\n",
      "> Querying with idx: 93f4fbfa-1d6a-4ed2-8abb-98aba87976d2: Ajout d'une Opération\n",
      "\n",
      "```sql\n",
      "INSERT INTO operations (nom_op, description_op,...\n",
      "> Querying with idx: 93f4fbfa-1d6a-4ed2-8abb-98aba87976d2: Ajout d'une Opération\n",
      "\n",
      "```sql\n",
      "INSERT INTO operations (nom_op, description_op,...\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "query = \"Je dois lancer un nouveau projet data avec mes données opérationnelles, qui puis-je impliquer, et pour faire quoi ?\"\n",
    "graph_query_engine = graph_index.as_query_engine(\n",
    " include_text=True,\n",
    " response_mode=\"tree_summarize\",\n",
    " embedding_mode=\"hybrid\",\n",
    " similarity_top_k=8,\n",
    ")\n",
    "\n",
    "response = graph_query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ff5382fd-1fc8-4faf-9356-c9bb3e478db5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour lancer un nouveau projet data avec vos données opérationnelles, vous pouvez impliquer plusieurs parties prenantes :\n",
       "\n",
       "1. **Équipes opérationnelles** : Elles peuvent être formées pour comprendre les nouvelles règles et processus liés au projet. Une formation est prévue pour ces équipes avant fin février 2025.\n",
       "\n",
       "2. **Responsables des opérations** : Ils peuvent être impliqués pour superviser l'intégration des données opérationnelles dans le Datawarehouse. Par exemple, un responsable comme Jean Dupont pourrait être désigné pour gérer des opérations spécifiques.\n",
       "\n",
       "3. **Équipe technique de l'ERP et du Datawarehouse** : Ces équipes peuvent travailler sur l'identification des champs critiques et prioritaires dans le Datawarehouse, ainsi que sur la mise en place de règles de validation automatique dans les processus ETL.\n",
       "\n",
       "4. **Gestionnaires de projets** : Ils peuvent être impliqués pour assurer que chaque opération est correctement liée à un projet spécifique, en utilisant des champs comme `id_projet` pour maintenir la traçabilité et la gestion des données.\n",
       "\n",
       "Ces parties prenantes joueront un rôle crucial dans la gestion, l'analyse, et l'intégration des données opérationnelles pour le succès du projet.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef119d0",
   "metadata": {},
   "source": [
    "# (Simple) Query the onto graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a8db6420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96369d42c4d74983a9df9bfd67e385dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "query = \"Je dois lancer un nouveau projet data avec mes données opérationnelles, qui puis-je impliquer, et pour faire quoi ?\"\n",
    "onto_query_engine = onto_index.as_query_engine(\n",
    " include_text=True,\n",
    " similarity_top_k=2,\n",
    ")\n",
    "\n",
    "response = onto_query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "adcd4265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour lancer un nouveau projet data avec vos données opérationnelles, vous pourriez impliquer Mme Sophie Laurent et M. Philippe Martin, car ils ont approuvé le compte rendu lié à la gestion des activités opérationnelles. Vous pourriez également envisager de travailler avec un rédacteur pour documenter le projet. Les étapes à suivre pourraient inclure un audit des données disponibles, le développement d'un accès personnalisé avec une interface d'utilisation, et l'organisation d'une session de formation pour l'utilisation des nouveaux outils.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582274ba",
   "metadata": {},
   "source": [
    "## (Node retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16db2a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = onto_index.as_retriever(\n",
    "    include_text=True,  # include source text, default True\n",
    ")\n",
    "\n",
    "nodes = retriever.retrieve(\"Je dois lancer un nouveau projet data avec mes données opérationnelles, qui puis-je impliquer, et pour faire quoi ?\")\n",
    "\n",
    "\n",
    "for node in nodes:\n",
    "    print(node.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a895520-d196-476f-b569-69a67484c120",
   "metadata": {},
   "source": [
    "# Have a real chat with your data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea3764d-a084-4f36-9d8c-3613aa9fd835",
   "metadata": {},
   "source": [
    "## Set up the engines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315a1c22-111b-4793-8a3d-bd3eae7e3ec7",
   "metadata": {},
   "source": [
    "### Graph engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "98b73cc2-0588-4b96-9aa2-1dfaf4cadb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ChatMemoryBuffer.from_defaults(token_limit=3900)\n",
    "graph_chat_engine = graph_index.as_chat_engine(\n",
    "    chat_mode=\"condense_plus_context\",\n",
    "    memory=memory,\n",
    "    llm=llm,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6897ec22",
   "metadata": {},
   "source": [
    "### Onto engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "54d04e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#onto_chat_engine = onto_index.query_engine(\n",
    "#    chat_mode=\"condense_plus_context\",\n",
    "#    llm=llm\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "709a37e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ChatMemoryBuffer.from_defaults(token_limit=3900)\n",
    "graph_chat_engine = graph_index.as_chat_engine(\n",
    "    chat_mode=\"condense_plus_context\",\n",
    "    memory=memory,\n",
    "    llm=llm,\n",
    "    context_prompt=(\n",
    "        \"Tu es un consultant spécialisé en stratégie et gouvernance des données.\"\n",
    "        \"Tu cites en priorité les métiers, les bases de données ou les champs de données présents dans ta base de connaissance.\"\n",
    "        \"Pour des idées de projets, tu vas proposer une stratégie et une gouvernance pour la mettre en oeuvre\"\n",
    "        \"Tu feras attention à mettre en avant le Return On Investment (ROI) du projet proposé\"\n",
    "    ),\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951e55a2-a9a9-4c4e-89a4-c4dfba55ebe4",
   "metadata": {},
   "source": [
    "### Vector engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1581c90c-cf5a-40d3-81b0-086238068f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ChatMemoryBuffer.from_defaults(token_limit=3900)\n",
    "vector_chat_engine = simple_index.as_chat_engine(\n",
    "    chat_mode=\"condense_plus_context\",\n",
    "    memory=memory,\n",
    "    llm=llm,\n",
    "    context_prompt=(\n",
    "        \"Tu es un consultant spécialisé en stratégie et gouvernance des données.\"\n",
    "        \"Pour des idées de projets, tu vas proposer une stratégie et une gouvernance pour la mettre en oeuvre\"\n",
    "        \"Tu feras attention à mettre en avant le Return On Investment (ROI) du projet proposé\"\n",
    "    ),\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3e0a08-f6ff-4ee6-a165-9b9fd90621fa",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "12804e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_chat_engine.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "da3e3ebf-18dc-4bdc-87dc-58d0227e9c18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.chat_engine.condense_plus_context:Condensed question: D'après tes connaissances et ta vision du monde, réponds moi aussi précisément que possible.Je dois lancer un nouveau projet data avec mes données opérationnelles, qui puis-je impliquer, et pour faire quoi ?\n",
      "Condensed question: D'après tes connaissances et ta vision du monde, réponds moi aussi précisément que possible.Je dois lancer un nouveau projet data avec mes données opérationnelles, qui puis-je impliquer, et pour faire quoi ?\n",
      "Condensed question: D'après tes connaissances et ta vision du monde, réponds moi aussi précisément que possible.Je dois lancer un nouveau projet data avec mes données opérationnelles, qui puis-je impliquer, et pour faire quoi ?\n",
      "Condensed question: D'après tes connaissances et ta vision du monde, réponds moi aussi précisément que possible.Je dois lancer un nouveau projet data avec mes données opérationnelles, qui puis-je impliquer, et pour faire quoi ?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65c776da6e0f4e39b2f166935b301335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response_stream = vector_chat_engine.stream_chat(\"\"\"D'après tes connaissances et ta vision du monde, réponds moi aussi précisément que possible.Je dois lancer un nouveau projet data avec mes données opérationnelles, qui puis-je impliquer, et pour faire quoi ?\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "91ebf21f-1990-4a4d-9c9a-868872f03042",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Lancer un projet data avec vos données opérationnelles est une initiative stratégique qui peut apporter une valeur significative à votre organisation. Voici une stratégie et une gouvernance pour mettre en œuvre ce projet, en mettant l'accent sur le ROI :\n",
      "\n",
      "### 1. **Constitution de l'équipe projet**\n",
      "\n",
      "#### a. **Sponsor Exécutif**\n",
      "   - **Rôle** : Fournir un soutien stratégique et des ressources nécessaires. Assurer l'alignement du projet avec les objectifs de l'entreprise.\n",
      "   - **ROI** : Garantit que le projet reste une priorité stratégique et reçoit le soutien nécessaire pour réussir.\n",
      "\n",
      "#### b. **Chef de Projet Data**\n",
      "   - **Rôle** : Gérer le projet au quotidien, coordonner les équipes, et assurer le respect des délais et du budget.\n",
      "   - **ROI** : Assure une exécution efficace et efficiente du projet, minimisant les coûts et maximisant les résultats.\n",
      "\n",
      "#### c. **Data Scientists et Analysts**\n",
      "   - **Rôle** : Analyser les données opérationnelles pour extraire des insights exploitables.\n",
      "   - **ROI** : Identifie des opportunités d'optimisation des processus et de réduction des coûts.\n",
      "\n",
      "#### d. **Ingénieurs Data**\n",
      "   - **Rôle** : Gérer l'infrastructure de données, assurer la qualité et l'intégrité des données.\n",
      "   - **ROI** : Réduit les erreurs de données et améliore la fiabilité des analyses, ce qui conduit à de meilleures décisions.\n",
      "\n",
      "#### e. **Experts Métier**\n",
      "   - **Rôle** : Apporter une connaissance approfondie des processus opérationnels et des besoins métiers.\n",
      "   - **ROI** : Assure que les analyses de données sont pertinentes et alignées sur les besoins réels de l'entreprise.\n",
      "\n",
      "#### f. **Responsable de la Gouvernance des Données**\n",
      "   - **Rôle** : Mettre en place des politiques de gouvernance des données, assurer la conformité et la sécurité des données.\n",
      "   - **ROI** : Réduit les risques liés à la non-conformité et protège la réputation de l'entreprise.\n",
      "\n",
      "### 2. **Stratégie de Mise en Œuvre**\n",
      "\n",
      "#### a. **Définition des Objectifs**\n",
      "   - Clarifier les objectifs du projet en termes de performance opérationnelle, réduction des coûts, ou amélioration de l'expérience client.\n",
      "\n",
      "#### b. **Évaluation des Données**\n",
      "   - Évaluer la qualité et la disponibilité des données opérationnelles. Identifier les lacunes et les opportunités d'amélioration.\n",
      "\n",
      "#### c. **Choix des Outils et Technologies**\n",
      "   - Sélectionner les outils d'analyse et de visualisation de données adaptés aux besoins du projet.\n",
      "\n",
      "#### d. **Développement de Cas d'Usage**\n",
      "   - Développer des cas d'usage spécifiques qui démontrent comment les données peuvent être utilisées pour atteindre les objectifs fixés.\n",
      "\n",
      "#### e. **Pilotage et Itération**\n",
      "   - Lancer des projets pilotes pour tester les hypothèses et affiner les modèles analytiques. Itérer en fonction des résultats obtenus.\n",
      "\n",
      "### 3. **Gouvernance des Données**\n",
      "\n",
      "#### a. **Politiques de Qualité des Données**\n",
      "   - Mettre en place des standards de qualité des données pour garantir des analyses fiables.\n",
      "\n",
      "#### b. **Sécurité et Conformité**\n",
      "   - Assurer la conformité avec les réglementations en matière de protection des données (ex. RGPD).\n",
      "\n",
      "#### c. **Formation et Sensibilisation**\n",
      "   - Former les employés sur l'importance de la gouvernance des données et les impliquer dans le processus.\n",
      "\n",
      "### 4. **Mesure du ROI**\n",
      "\n",
      "- **Indicateurs de Performance** : Définir des KPIs pour mesurer l'impact du projet sur les opérations, tels que la réduction des coûts, l'amélioration de l'efficacité, ou l'augmentation de la satisfaction client.\n",
      "- **Rapports Réguliers** : Mettre en place des rapports réguliers pour suivre les progrès et ajuster la stratégie si nécessaire.\n",
      "\n",
      "En impliquant les bonnes parties prenantes et en mettant en place une gouvernance solide, vous pouvez maximiser le ROI de votre projet data et transformer vos données opérationnelles en un atout stratégique."
     ]
    }
   ],
   "source": [
    "generate = response_stream.print_response_stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5a056a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>None</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{generate}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6660a81e-ad67-4d44-a86d-0ad7b77f626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_modele = \"\"\" \n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9c0e462e-d3ee-463a-8d49-f09dc2396b8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.core.chat_engine.condense_plus_context:Condensed question: D'après tes connaissances et ta vision du monde, quel serait le schéma de données idéal pour un projet data utilisant des données opérationnelles, en utilisant le schéma de données standard Frictionless pour le décrire ? Peux-tu imiter le style d'écriture de la {section_modele} ?\n",
      "Condensed question: D'après tes connaissances et ta vision du monde, quel serait le schéma de données idéal pour un projet data utilisant des données opérationnelles, en utilisant le schéma de données standard Frictionless pour le décrire ? Peux-tu imiter le style d'écriture de la {section_modele} ?\n",
      "Condensed question: D'après tes connaissances et ta vision du monde, quel serait le schéma de données idéal pour un projet data utilisant des données opérationnelles, en utilisant le schéma de données standard Frictionless pour le décrire ? Peux-tu imiter le style d'écriture de la {section_modele} ?\n",
      "Condensed question: D'après tes connaissances et ta vision du monde, quel serait le schéma de données idéal pour un projet data utilisant des données opérationnelles, en utilisant le schéma de données standard Frictionless pour le décrire ? Peux-tu imiter le style d'écriture de la {section_modele} ?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b119b01379a14c0f81958cc1fc38529b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response_stream = vector_chat_engine.stream_chat(\"\"\"D'après tes connaissances et ta vision du monde, réponds moi aussi précisément que possible, quel serait le schéma de données idéal pour ce projet. Utilise le schéma de données standard Frictionless pour le décrire. Imite le style d'écriture de la {section_modele}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c86075ee-12c8-4b97-8b51-0c717fc4b1d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Pour concevoir un schéma de données idéal pour votre projet en utilisant le standard Frictionless, il est essentiel de structurer vos données de manière à maximiser leur utilité et leur interopérabilité. Voici un exemple de schéma de données en utilisant le format Frictionless, qui est un standard ouvert pour la gestion des données tabulaires :\n",
      "\n",
      "### {section_modele}\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"profile\": \"tabular-data-package\",\n",
      "  \"name\": \"operational-data-project\",\n",
      "  \"resources\": [\n",
      "    {\n",
      "      \"name\": \"operations\",\n",
      "      \"path\": \"data/operations.csv\",\n",
      "      \"schema\": {\n",
      "        \"fields\": [\n",
      "          {\n",
      "            \"name\": \"operation_id\",\n",
      "            \"type\": \"integer\",\n",
      "            \"description\": \"Unique identifier for each operation\"\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"operation_date\",\n",
      "            \"type\": \"date\",\n",
      "            \"format\": \"yyyy-mm-dd\",\n",
      "            \"description\": \"Date of the operation\"\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"operation_type\",\n",
      "            \"type\": \"string\",\n",
      "            \"constraints\": {\n",
      "              \"enum\": [\"type1\", \"type2\", \"type3\"]\n",
      "            },\n",
      "            \"description\": \"Type of operation\"\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"department\",\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"Department responsible for the operation\"\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"cost\",\n",
      "            \"type\": \"number\",\n",
      "            \"description\": \"Cost associated with the operation\"\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"duration\",\n",
      "            \"type\": \"number\",\n",
      "            \"description\": \"Duration of the operation in hours\"\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"outcome\",\n",
      "            \"type\": \"string\",\n",
      "            \"constraints\": {\n",
      "              \"enum\": [\"success\", \"failure\", \"pending\"]\n",
      "            },\n",
      "            \"description\": \"Outcome of the operation\"\n",
      "          }\n",
      "        ],\n",
      "        \"primaryKey\": \"operation_id\",\n",
      "        \"foreignKeys\": [\n",
      "          {\n",
      "            \"fields\": \"department\",\n",
      "            \"reference\": {\n",
      "              \"resource\": \"departments\",\n",
      "              \"fields\": \"department_id\"\n",
      "            }\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"departments\",\n",
      "      \"path\": \"data/departments.csv\",\n",
      "      \"schema\": {\n",
      "        \"fields\": [\n",
      "          {\n",
      "            \"name\": \"department_id\",\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"Unique identifier for each department\"\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"department_name\",\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"Name of the department\"\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"manager\",\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"Manager of the department\"\n",
      "          }\n",
      "        ],\n",
      "        \"primaryKey\": \"department_id\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "### Explication du Schéma\n",
      "\n",
      "- **Profile** : Indique que le schéma suit le format \"tabular-data-package\", qui est adapté pour les données tabulaires.\n",
      "- **Resources** : Contient deux ressources principales, `operations` et `departments`, chacune représentant une table de données.\n",
      "- **Fields** : Chaque champ est défini avec un `name`, `type`, et `description`, ce qui facilite la compréhension et l'utilisation des données.\n",
      "- **PrimaryKey** : Assure l'unicité des enregistrements dans chaque table.\n",
      "- **ForeignKeys** : Établit des relations entre les tables, permettant des jointures et des analyses plus complexes.\n",
      "\n",
      "### Avantages du Schéma\n",
      "\n",
      "- **Interopérabilité** : Le format Frictionless est largement reconnu et facilite l'échange de données entre systèmes.\n",
      "- **Clarté** : Les descriptions et les contraintes rendent le schéma facile à comprendre et à utiliser par les parties prenantes.\n",
      "- **Flexibilité** : Le schéma peut être étendu pour inclure d'autres types de données ou de relations au fur et à mesure que le projet évolue.\n",
      "\n",
      "En adoptant ce schéma de données, vous assurez une base solide pour l'analyse de vos données opérationnelles, ce qui peut conduire à des insights précieux et à un ROI amélioré."
     ]
    }
   ],
   "source": [
    "generate = response_stream.print_response_stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ffb78d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>None</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{generate}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f74a302-bb28-4bf8-9103-1f62750a5fc0",
   "metadata": {},
   "source": [
    "## Sum-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d81f7480-9d62-4952-948e-19e089d9da9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = memory.get_all()\n",
    "\n",
    "# Assuming chat_history is available and contains your messages\n",
    "assistant_messages = [\n",
    "    message.content \n",
    "    for message in chat_history \n",
    "    if message.role == MessageRole.ASSISTANT  # Compare with the enum directly\n",
    "]\n",
    "\n",
    "\n",
    "output_filename = r\"/Users/arthursarazin/Documents/coreandgraphs/graphandgovern/output116n87e.md\"\n",
    "# Write to a Markdown file\n",
    "with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    for msg in assistant_messages:\n",
    "        f.write(msg + \"\\n\\n\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
